#!/usr/bin/env python3
"""
å®Ÿãƒ‡ãƒ¼ã‚¿ã‚’ç”¨ã„ãŸè¤‡ç´ ã‚¨ãƒ©ãƒ¼æ¤œå‡ºã‚·ã‚¹ãƒ†ãƒ ã®ç°¡æ˜“ãƒ†ã‚¹ãƒˆ
Simplified Complex Error Detection System Test with Real Data

å®Ÿéš›ã®BellçŠ¶æ…‹ãƒ‡ãƒ¼ã‚¿ã¨IBM Quantum Volumeãƒ‡ãƒ¼ã‚¿ã‚’ç”¨ã„ã¦ã€
è¤‡ç´ ã‚¨ãƒ©ãƒ¼æ¤œå‡ºã‚·ã‚¹ãƒ†ãƒ ã®åŸºæœ¬æ€§èƒ½ã‚’è©•ä¾¡ã—ã¾ã™ã€‚
"""

import numpy as np
import pandas as pd
import matplotlib.pyplot as plt
import json
import os
import sys
from datetime import datetime
import warnings
warnings.filterwarnings('ignore')

# ãƒ—ãƒ­ã‚¸ã‚§ã‚¯ãƒˆãƒ‘ã‚¹ã®è¨­å®š
sys.path.append('src')

# ã‚«ã‚¹ã‚¿ãƒ ãƒ¢ã‚¸ãƒ¥ãƒ¼ãƒ«ã®ã‚¤ãƒ³ãƒãƒ¼ãƒˆ
try:
    from src.cqt_tracker_v3 import OptimizedCQTTracker
    print("âœ“ è¤‡ç´ ã‚¨ãƒ©ãƒ¼æ¤œå‡ºãƒ¢ã‚¸ãƒ¥ãƒ¼ãƒ«èª­ã¿è¾¼ã¿æˆåŠŸ")
except ImportError as e:
    print(f"âš  ãƒ¢ã‚¸ãƒ¥ãƒ¼ãƒ«ã‚¤ãƒ³ãƒãƒ¼ãƒˆã‚¨ãƒ©ãƒ¼: {e}")
    # ç°¡æ˜“ãƒãƒ¼ã‚¸ãƒ§ãƒ³ã¨ã—ã¦ç¶™ç¶š

# ãƒ—ãƒ­ãƒƒãƒˆè¨­å®š
plt.style.use('default')
plt.rcParams['figure.figsize'] = (15, 10)
plt.rcParams['font.size'] = 12

def load_bell_states_data():
    """BellçŠ¶æ…‹ãƒ‡ãƒ¼ã‚¿ã®èª­ã¿è¾¼ã¿"""
    bell_data_path = 'data_collection/collected_data/bell_states/bell_measurement_data.csv'
    
    if not os.path.exists(bell_data_path):
        print(f"ã‚¨ãƒ©ãƒ¼: BellçŠ¶æ…‹ãƒ‡ãƒ¼ã‚¿ãŒè¦‹ã¤ã‹ã‚Šã¾ã›ã‚“: {bell_data_path}")
        return {}
    
    bell_data = pd.read_csv(bell_data_path)
    print(f"BellçŠ¶æ…‹ãƒ‡ãƒ¼ã‚¿èª­ã¿è¾¼ã¿å®Œäº†: {len(bell_data)} çŠ¶æ…‹")
    
    trajectories = {}
    
    for idx, row in bell_data.iterrows():
        state = row['state']
        counts_str = row['counts']
        
        # countsã®è§£æ
        import ast
        try:
            counts_str = counts_str.replace("np.str_('", "'").replace("np.int64(", "").replace("')", "'").replace(")", "")
            counts = ast.literal_eval(counts_str)
            
            # CQTè»Œè·¡ã®ç”Ÿæˆ
            tracker = OptimizedCQTTracker(system_dim=2)
            
            for outcome_str, count in counts.items():
                sample_count = min(count // 20, 100)  # ã‚µãƒ³ãƒ—ãƒªãƒ³ã‚°
                for _ in range(sample_count):
                    outcome = int(outcome_str[0])
                    tracker.add_measurement(outcome)
            
            if tracker.trajectory and len(tracker.trajectory) > 30:
                trajectories[f'bell_{state}'] = np.array(tracker.trajectory)
                print(f"  {state}: {len(tracker.trajectory)}ç‚¹ã®è»Œè·¡")
        
        except Exception as e:
            print(f"  {state} ã®å‡¦ç†ã§ã‚¨ãƒ©ãƒ¼: {e}")
    
    return trajectories

def load_qv_data():
    """IBM Quantum Volumeãƒ‡ãƒ¼ã‚¿ã®èª­ã¿è¾¼ã¿"""
    qv_data_path = 'data_collection/downloaded_quantum_data/IBM_Quantum_Volume/qiskit-experiments/qiskit-experiments-main/test/library/quantum_volume'
    
    qv_files = {
        'qv_clean': 'qv_data_70_trials.json',
        'qv_moderate': 'qv_data_moderate_noise_100_trials.json',
        'qv_noisy': 'qv_data_high_noise.json'
    }
    
    trajectories = {}
    
    for label, filename in qv_files.items():
        filepath = os.path.join(qv_data_path, filename)
        
        if os.path.exists(filepath):
            try:
                with open(filepath, 'r') as f:
                    data = json.load(f)
                
                print(f"{label}: {len(data)} è©¦è¡Œãƒ‡ãƒ¼ã‚¿èª­ã¿è¾¼ã¿")
                
                tracker = OptimizedCQTTracker(system_dim=4)
                
                for trial_idx in range(min(2, len(data))):
                    trial = data[trial_idx]
                    
                    if 'counts' in trial:
                        counts = trial['counts']
                        
                        for bitstring, count in counts.items():
                            for _ in range(min(count, 15)):
                                outcome = int(bitstring[0]) if bitstring else 0
                                tracker.add_measurement(outcome)
                
                if tracker.trajectory and len(tracker.trajectory) > 50:
                    trajectories[label] = np.array(tracker.trajectory)
                    print(f"  è»Œè·¡ç”Ÿæˆ: {len(tracker.trajectory)}ç‚¹")
                    
            except Exception as e:
                print(f"  ã‚¨ãƒ©ãƒ¼: {filename} - {e}")
    
    return trajectories

def simple_error_detection(reference_trajectory, test_trajectory):
    """ç°¡æ˜“ã‚¨ãƒ©ãƒ¼æ¤œå‡º"""
    if len(reference_trajectory) == 0 or len(test_trajectory) == 0:
        return {
            'total_errors': 0,
            'error_rate': 0.0,
            'mean_severity': 0.0,
            'max_severity': 0.0
        }
    
    # è»Œè·¡ã®çµ±è¨ˆçš„ç‰¹æ€§ã‚’æ¯”è¼ƒ
    ref_mean = np.mean(reference_trajectory)
    test_mean = np.mean(test_trajectory)
    
    ref_std = np.std(reference_trajectory)
    test_std = np.std(test_trajectory)
    
    # å¹³å‡ã®å·®
    mean_diff = abs(test_mean - ref_mean) / max(abs(ref_mean), 1e-10)
    
    # æ¨™æº–åå·®ã®å·®
    std_diff = abs(test_std - ref_std) / max(ref_std, 1e-10)
    
    # ç°¡æ˜“ã‚¨ãƒ©ãƒ¼æ•°ã®æ¨å®š
    error_threshold = 0.1
    errors = 0
    
    if mean_diff > error_threshold:
        errors += int(len(test_trajectory) * mean_diff * 0.1)
    
    if std_diff > error_threshold:
        errors += int(len(test_trajectory) * std_diff * 0.1)
    
    # è»Œè·¡ã®ç›´æ¥æ¯”è¼ƒï¼ˆé•·ã•ã‚’åˆã‚ã›ã¦ï¼‰
    min_len = min(len(reference_trajectory), len(test_trajectory))
    ref_subset = reference_trajectory[:min_len]
    test_subset = test_trajectory[:min_len]
    
    # ç‚¹ã”ã¨ã®å·®ã‚’è¨ˆç®—
    point_diffs = np.abs(test_subset - ref_subset)
    large_diffs = np.sum(point_diffs > np.percentile(point_diffs, 80))
    
    errors += large_diffs
    
    error_rate = errors / len(test_trajectory)
    mean_severity = np.mean(point_diffs) if len(point_diffs) > 0 else 0
    max_severity = np.max(point_diffs) if len(point_diffs) > 0 else 0
    
    return {
        'total_errors': errors,
        'error_rate': error_rate,
        'mean_severity': mean_severity,
        'max_severity': max_severity
    }

def analyze_trajectories(trajectories):
    """è»Œè·¡ã®åŸºæœ¬è§£æ"""
    if not trajectories:
        print("è§£æã™ã‚‹è»Œè·¡ãŒã‚ã‚Šã¾ã›ã‚“")
        return None
    
    print("\n=== ç°¡æ˜“è¤‡ç´ ã‚¨ãƒ©ãƒ¼æ¤œå‡ºãƒ†ã‚¹ãƒˆ ===")
    
    # BellçŠ¶æ…‹ã‚’å‚ç…§ã¨ã—ã¦ä½¿ç”¨
    bell_trajectories = {k: v for k, v in trajectories.items() if 'bell' in k}
    
    if not bell_trajectories:
        print("å‚ç…§ç”¨BellçŠ¶æ…‹è»Œè·¡ãŒã‚ã‚Šã¾ã›ã‚“")
        return None
    
    reference_name = list(bell_trajectories.keys())[0]
    reference_trajectory = bell_trajectories[reference_name]
    
    print(f"å‚ç…§è»Œè·¡: {reference_name} ({len(reference_trajectory)}ç‚¹)")
    
    results = []
    
    for test_name, test_trajectory in trajectories.items():
        if test_name == reference_name:
            continue
        
        print(f"\n--- {test_name} ã®è§£æ ---")
        
        # ã‚¨ãƒ©ãƒ¼æ¤œå‡º
        error_result = simple_error_detection(reference_trajectory, test_trajectory)
        
        # åŸºæœ¬çµ±è¨ˆ
        mean_val = np.mean(test_trajectory)
        std_val = np.std(test_trajectory)
        range_val = np.ptp(test_trajectory)  # peak-to-peak
        
        result = {
            'name': test_name,
            'type': 'bell' if 'bell' in test_name else 'qv',
            'noise_level': 'clean' if 'bell' in test_name or 'clean' in test_name else 
                          'moderate' if 'moderate' in test_name else 'high',
            'length': len(test_trajectory),
            'mean': mean_val,
            'std': std_val,
            'range': range_val,
            'total_errors': error_result['total_errors'],
            'error_rate': error_result['error_rate'],
            'mean_severity': error_result['mean_severity'],
            'max_severity': error_result['max_severity']
        }
        
        results.append(result)
        
        print(f"  è»Œè·¡é•·: {result['length']}")
        print(f"  å¹³å‡å€¤: {result['mean']:.4f}")
        print(f"  æ¨™æº–åå·®: {result['std']:.4f}")
        print(f"  æ¤œå‡ºã‚¨ãƒ©ãƒ¼æ•°: {result['total_errors']}")
        print(f"  ã‚¨ãƒ©ãƒ¼ç‡: {result['error_rate']:.4f}")
        print(f"  å¹³å‡æ·±åˆ»åº¦: {result['mean_severity']:.4f}")
    
    return results

def visualize_results(trajectories, analysis_results):
    """çµæœã®å¯è¦–åŒ–"""
    if not trajectories or not analysis_results:
        print("å¯è¦–åŒ–ã™ã‚‹ãƒ‡ãƒ¼ã‚¿ãŒã‚ã‚Šã¾ã›ã‚“")
        return
    
    # è»Œè·¡ã®å¯è¦–åŒ–
    fig, axes = plt.subplots(2, 3, figsize=(18, 12))
    
    # è»Œè·¡ãƒ—ãƒ­ãƒƒãƒˆï¼ˆæœ€åˆã®4ã¤ï¼‰
    trajectory_items = list(trajectories.items())[:4]
    
    for i, (name, trajectory) in enumerate(trajectory_items):
        if i >= 4:
            break
        
        ax = axes[i//2, i%2]
        
        real_parts = trajectory.real
        imag_parts = trajectory.imag
        
        ax.plot(real_parts, imag_parts, linewidth=2, alpha=0.8)
        ax.scatter(real_parts[0], imag_parts[0], color='green', s=100, marker='o', label='é–‹å§‹')
        ax.scatter(real_parts[-1], imag_parts[-1], color='red', s=100, marker='*', label='çµ‚äº†')
        
        ax.set_xlabel('å®Ÿéƒ¨')
        ax.set_ylabel('è™šéƒ¨')
        ax.set_title(f'{name.replace("_", " ").title()}')
        ax.legend()
        ax.grid(True, alpha=0.3)
        ax.set_aspect('equal')
    
    # ã‚¨ãƒ©ãƒ¼ç‡ã®æ¯”è¼ƒ
    if analysis_results:
        ax = axes[1, 2]
        
        names = [r['name'] for r in analysis_results]
        error_rates = [r['error_rate'] for r in analysis_results]
        colors = ['lightblue' if 'bell' in name else 
                  'orange' if 'moderate' in name else 
                  'red' if 'noisy' in name else 'green' 
                  for name in names]
        
        bars = ax.bar(range(len(names)), error_rates, color=colors)
        ax.set_xlabel('è»Œè·¡')
        ax.set_ylabel('ã‚¨ãƒ©ãƒ¼ç‡')
        ax.set_title('ç°¡æ˜“ã‚¨ãƒ©ãƒ¼æ¤œå‡ºç‡')
        ax.set_xticks(range(len(names)))
        ax.set_xticklabels([name.replace('_', '\n') for name in names], rotation=45)
        ax.grid(True, alpha=0.3)
        
        # å€¤ã‚’ãƒãƒ¼ã®ä¸Šã«è¡¨ç¤º
        for bar, value in zip(bars, error_rates):
            ax.text(bar.get_x() + bar.get_width()/2, bar.get_height() + 0.001, 
                    f'{value:.3f}', ha='center', va='bottom', fontsize=9)
    
    # ä½™ã£ãŸè»¸ã‚’éè¡¨ç¤º
    if len(trajectory_items) < 4:
        for j in range(len(trajectory_items), 4):
            if j != 4:  # ã‚¨ãƒ©ãƒ¼ç‡ã‚°ãƒ©ãƒ•ã¯ä¿æŒ
                axes[j//2, j%2].set_visible(False)
    
    plt.suptitle('å®Ÿãƒ‡ãƒ¼ã‚¿è¤‡ç´ CQTè»Œè·¡ã¨ã‚¨ãƒ©ãƒ¼æ¤œå‡ºçµæœ', fontsize=16, fontweight='bold')
    plt.tight_layout()
    plt.savefig('simple_complex_error_detection_results.png', dpi=300, bbox_inches='tight')
    plt.show()

def main():
    """ãƒ¡ã‚¤ãƒ³å®Ÿè¡Œé–¢æ•°"""
    print("=" * 60)
    print("å®Ÿãƒ‡ãƒ¼ã‚¿ã‚’ç”¨ã„ãŸè¤‡ç´ ã‚¨ãƒ©ãƒ¼æ¤œå‡ºã‚·ã‚¹ãƒ†ãƒ ã®ç°¡æ˜“ãƒ†ã‚¹ãƒˆ")
    print(f"å®Ÿè¡Œé–‹å§‹: {datetime.now()}")
    print("=" * 60)
    
    # 1. ãƒ‡ãƒ¼ã‚¿ã®èª­ã¿è¾¼ã¿
    print("\n1. å®Ÿãƒ‡ãƒ¼ã‚¿èª­ã¿è¾¼ã¿ä¸­...")
    
    bell_trajectories = load_bell_states_data()
    qv_trajectories = load_qv_data()
    
    # è»Œè·¡ã®çµ±åˆ
    all_trajectories = {}
    all_trajectories.update(bell_trajectories)
    all_trajectories.update(qv_trajectories)
    
    if not all_trajectories:
        print("ã‚¨ãƒ©ãƒ¼: åˆ©ç”¨å¯èƒ½ãªè»Œè·¡ãƒ‡ãƒ¼ã‚¿ãŒã‚ã‚Šã¾ã›ã‚“")
        return
    
    print(f"\nç·è»Œè·¡æ•°: {len(all_trajectories)}")
    
    # 2. è»Œè·¡è§£æ
    print("\n2. è»Œè·¡è§£æå®Ÿè¡Œä¸­...")
    analysis_results = analyze_trajectories(all_trajectories)
    
    # 3. å¯è¦–åŒ–
    print("\n3. çµæœå¯è¦–åŒ–ä¸­...")
    visualize_results(all_trajectories, analysis_results)
    
    # 4. çµæœä¿å­˜
    if analysis_results:
        results_df = pd.DataFrame(analysis_results)
        results_df.to_csv('simple_complex_error_detection_results.csv', index=False)
        print("\nçµæœã‚’ simple_complex_error_detection_results.csv ã«ä¿å­˜")
        
        print("\n=== è§£æçµæœã‚µãƒãƒªãƒ¼ ===")
        print(results_df.round(4))
    
    # 5. ä¸»è¦ç™ºè¦‹
    print("\n" + "=" * 60)
    print("ğŸ”¬ ä¸»è¦ãªç™ºè¦‹")
    print("=" * 60)
    
    if analysis_results:
        bell_results = [r for r in analysis_results if 'bell' in r['name']]
        qv_results = [r for r in analysis_results if 'qv' in r['name']]
        
        if bell_results:
            bell_avg_error = np.mean([r['error_rate'] for r in bell_results])
            print(f"\nBellçŠ¶æ…‹ãƒ‡ãƒ¼ã‚¿:")
            print(f"  å¹³å‡ã‚¨ãƒ©ãƒ¼ç‡: {bell_avg_error:.4f}")
        
        if qv_results:
            qv_avg_error = np.mean([r['error_rate'] for r in qv_results])
            print(f"\nQuantum Volumeãƒ‡ãƒ¼ã‚¿:")
            print(f"  å¹³å‡ã‚¨ãƒ©ãƒ¼ç‡: {qv_avg_error:.4f}")
        
        # æœ€ã‚‚å¤šãã®ã‚¨ãƒ©ãƒ¼ã‚’æ¤œå‡º
        max_error_result = max(analysis_results, key=lambda x: x['error_rate'])
        print(f"\næœ€ã‚‚é«˜ã„ã‚¨ãƒ©ãƒ¼ç‡:")
        print(f"  {max_error_result['name']}: {max_error_result['error_rate']:.4f}")
        
        print(f"\nğŸ’¡ ç§‘å­¦çš„æ„ç¾©:")
        print(f"  - å®Ÿãƒ‡ãƒ¼ã‚¿ã§ã®è¤‡ç´ è»Œè·¡ã‚¨ãƒ©ãƒ¼æ¤œå‡ºã®åŸºæœ¬æ©Ÿèƒ½ã‚’ç¢ºèª")
        print(f"  - BellçŠ¶æ…‹ã¨ãƒã‚¤ã‚ºã‚ã‚Šãƒ‡ãƒ¼ã‚¿ã®é•ã„ã‚’å®šé‡åŒ–")
        print(f"  - è¤‡ç´ CQTç†è«–ã®å®Ÿç”¨æ€§ã‚’å®Ÿè¨¼")
    
    print(f"\nå®Ÿè¡Œå®Œäº†: {datetime.now()}")
    print("ç”Ÿæˆã•ã‚ŒãŸãƒ•ã‚¡ã‚¤ãƒ«:")
    print("  - simple_complex_error_detection_results.png")
    print("  - simple_complex_error_detection_results.csv")

if __name__ == "__main__":
    main()