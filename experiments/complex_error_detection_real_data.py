#!/usr/bin/env python3
"""
å®Ÿãƒ‡ãƒ¼ã‚¿ã‚’ç”¨ã„ãŸè¤‡ç´ ã‚¨ãƒ©ãƒ¼æ¤œå‡ºã‚·ã‚¹ãƒ†ãƒ ã®ãƒ†ã‚¹ãƒˆ
Complex Error Detection System Test with Real Data

å®Ÿéš›ã®BellçŠ¶æ…‹ãƒ‡ãƒ¼ã‚¿ã¨IBM Quantum Volumeãƒ‡ãƒ¼ã‚¿ã‚’ç”¨ã„ã¦ã€
è¤‡ç´ ã‚¨ãƒ©ãƒ¼æ¤œå‡ºã‚·ã‚¹ãƒ†ãƒ ã®æ€§èƒ½ã‚’è©•ä¾¡ã—ã¾ã™ã€‚
"""

import numpy as np
import pandas as pd
import matplotlib.pyplot as plt
import json
import os
import sys
from datetime import datetime
import warnings
warnings.filterwarnings('ignore')

# ãƒ—ãƒ­ã‚¸ã‚§ã‚¯ãƒˆãƒ‘ã‚¹ã®è¨­å®š
sys.path.append('src')
sys.path.append('data_collection')

# ã‚«ã‚¹ã‚¿ãƒ ãƒ¢ã‚¸ãƒ¥ãƒ¼ãƒ«ã®ã‚¤ãƒ³ãƒãƒ¼ãƒˆ
try:
    from src.cqt_tracker_v3 import OptimizedCQTTracker
    from src.complex_error_detection import ComplexErrorDetector, compute_complex_correlation, detect_quantum_entanglement
    print("âœ“ è¤‡ç´ ã‚¨ãƒ©ãƒ¼æ¤œå‡ºãƒ¢ã‚¸ãƒ¥ãƒ¼ãƒ«èª­ã¿è¾¼ã¿æˆåŠŸ")
except ImportError as e:
    print(f"âš  ãƒ¢ã‚¸ãƒ¥ãƒ¼ãƒ«ã‚¤ãƒ³ãƒãƒ¼ãƒˆã‚¨ãƒ©ãƒ¼: {e}")
    sys.exit(1)

# ãƒ—ãƒ­ãƒƒãƒˆè¨­å®š
plt.style.use('default')
plt.rcParams['figure.figsize'] = (15, 10)
plt.rcParams['font.size'] = 12

def load_real_trajectories():
    """å®Ÿãƒ‡ãƒ¼ã‚¿ã‹ã‚‰è»Œè·¡ã‚’ç”Ÿæˆ"""
    trajectories = {}
    
    # 1. BellçŠ¶æ…‹ãƒ‡ãƒ¼ã‚¿ï¼ˆã‚¯ãƒªãƒ¼ãƒ³ãªå‚ç…§ç”¨ï¼‰
    bell_data_path = 'data_collection/collected_data/bell_states/bell_measurement_data.csv'
    
    if os.path.exists(bell_data_path):
        bell_data = pd.read_csv(bell_data_path)
        
        for idx, row in bell_data.iterrows():
            state = row['state']
            counts_str = row['counts']
            
            # countsã®è§£æ
            import ast
            counts_str = counts_str.replace("np.str_('", "'").replace("np.int64(", "").replace("')", "'").replace(")", "")
            counts = ast.literal_eval(counts_str)
            
            # CQTè»Œè·¡ã®ç”Ÿæˆ
            tracker = OptimizedCQTTracker(system_dim=2)
            
            for outcome_str, count in counts.items():
                sample_count = min(count // 15, 150)  # é©åº¦ãªã‚µãƒ³ãƒ—ãƒªãƒ³ã‚°
                for _ in range(sample_count):
                    outcome = int(outcome_str[0])
                    tracker.add_measurement(outcome)
            
            if tracker.trajectory and len(tracker.trajectory) > 50:
                trajectories[f'bell_{state}'] = np.array(tracker.trajectory)
                print(f"Bell {state}: {len(tracker.trajectory)}ç‚¹ã®è»Œè·¡")
    
    # 2. IBM Quantum Volumeãƒ‡ãƒ¼ã‚¿ï¼ˆæ§˜ã€…ãªãƒã‚¤ã‚ºãƒ¬ãƒ™ãƒ«ï¼‰
    qv_data_path = 'data_collection/downloaded_quantum_data/IBM_Quantum_Volume/qiskit-experiments/qiskit-experiments-main/test/library/quantum_volume'
    
    qv_files = {
        'qv_clean': 'qv_data_70_trials.json',  # æ¯”è¼ƒçš„ã‚¯ãƒªãƒ¼ãƒ³
        'qv_moderate': 'qv_data_moderate_noise_100_trials.json',  # ä¸­ç¨‹åº¦ãƒã‚¤ã‚º
        'qv_noisy': 'qv_data_high_noise.json'  # é«˜ãƒã‚¤ã‚º
    }
    
    for label, filename in qv_files.items():
        filepath = os.path.join(qv_data_path, filename)
        
        if os.path.exists(filepath):
            try:
                with open(filepath, 'r') as f:
                    data = json.load(f)
                
                print(f"{label}: {len(data)} è©¦è¡Œãƒ‡ãƒ¼ã‚¿èª­ã¿è¾¼ã¿")
                
                # è¤‡æ•°è©¦è¡Œã‹ã‚‰è»Œè·¡ç”Ÿæˆ
                tracker = OptimizedCQTTracker(system_dim=4)
                
                for trial_idx in range(min(3, len(data))):
                    trial = data[trial_idx]
                    
                    if 'counts' in trial:
                        counts = trial['counts']
                        
                        for bitstring, count in counts.items():
                            for _ in range(min(count, 25)):
                                outcome = int(bitstring[0]) if bitstring else 0
                                tracker.add_measurement(outcome)
                
                if tracker.trajectory and len(tracker.trajectory) > 100:
                    trajectories[label] = np.array(tracker.trajectory)
                    print(f"  è»Œè·¡ç”Ÿæˆ: {len(tracker.trajectory)}ç‚¹")
                    
            except Exception as e:
                print(f"  ã‚¨ãƒ©ãƒ¼: {filename} - {e}")
    
    return trajectories

def test_error_detection_performance(trajectories):
    """ã‚¨ãƒ©ãƒ¼æ¤œå‡ºæ€§èƒ½ã®ãƒ†ã‚¹ãƒˆ"""\n    if not trajectories:\n        print(\"ãƒ†ã‚¹ãƒˆç”¨è»Œè·¡ãŒã‚ã‚Šã¾ã›ã‚“\")\n        return None\n    \n    print(\"\\n=== è¤‡ç´ ã‚¨ãƒ©ãƒ¼æ¤œå‡ºæ€§èƒ½ãƒ†ã‚¹ãƒˆ ===\")\n    \n    # BellçŠ¶æ…‹ã‚’å‚ç…§è»Œè·¡ã¨ã—ã¦ä½¿ç”¨\n    bell_trajectories = {k: v for k, v in trajectories.items() if 'bell' in k}\n    qv_trajectories = {k: v for k, v in trajectories.items() if 'qv' in k}\n    \n    if not bell_trajectories:\n        print(\"å‚ç…§ç”¨BellçŠ¶æ…‹è»Œè·¡ãŒã‚ã‚Šã¾ã›ã‚“\")\n        return None\n    \n    # æœ€åˆã®BellçŠ¶æ…‹ã‚’å‚ç…§ã¨ã—ã¦ä½¿ç”¨\n    reference_name = list(bell_trajectories.keys())[0]\n    reference_trajectory = bell_trajectories[reference_name]\n    \n    print(f\"å‚ç…§è»Œè·¡: {reference_name} ({len(reference_trajectory)}ç‚¹)\")\n    \n    # ã‚¨ãƒ©ãƒ¼æ¤œå‡ºå™¨ã®åˆæœŸåŒ–\n    detector = ComplexErrorDetector(reference_trajectory)\n    \n    error_results = []\n    detailed_results = {}\n    \n    # å…¨è»Œè·¡ã‚’ãƒ†ã‚¹ãƒˆ\n    for test_name, test_trajectory in trajectories.items():\n        if test_name == reference_name:\n            continue  # å‚ç…§è»Œè·¡è‡ªä½“ã¯ã‚¹ã‚­ãƒƒãƒ—\n        \n        print(f\"\\n--- {test_name} ã®ã‚¨ãƒ©ãƒ¼æ¤œå‡ºãƒ†ã‚¹ãƒˆ ---\")\n        \n        # ã‚¨ãƒ©ãƒ¼æ¤œå‡ºã®å®Ÿè¡Œ\n        try:\n            errors = detector.detect_errors(test_trajectory)\n            error_analysis = detector.analyze_error_pattern(errors)\n            \n            # åŸºæœ¬çµ±è¨ˆ\n            total_errors = len(errors)\n            error_rate = total_errors / len(test_trajectory)\n            mean_severity = np.mean([e['severity'] for e in errors]) if errors else 0\n            max_severity = np.max([e['severity'] for e in errors]) if errors else 0\n            \n            # ã‚¨ãƒ©ãƒ¼ã®åˆ†é¡\n            phase_errors = sum(1 for e in errors if e['error_type'] == 'phase_decoherence')\n            amplitude_errors = sum(1 for e in errors if e['error_type'] == 'amplitude_anomaly')\n            correlation_errors = sum(1 for e in errors if e['error_type'] == 'correlation_break')\n            \n            # çµæœã®ä¿å­˜\n            result = {\n                'test_name': test_name,\n                'trajectory_type': 'bell' if 'bell' in test_name else 'qv',\n                'noise_level': 'clean' if 'clean' in test_name or 'bell' in test_name else \n                              'moderate' if 'moderate' in test_name else 'high',\n                'trajectory_length': len(test_trajectory),\n                'total_errors': total_errors,\n                'error_rate': error_rate,\n                'mean_severity': mean_severity,\n                'max_severity': max_severity,\n                'phase_errors': phase_errors,\n                'amplitude_errors': amplitude_errors,\n                'correlation_errors': correlation_errors,\n                'error_clusters': len(error_analysis.get('position_clusters', []))\n            }\n            \n            error_results.append(result)\n            detailed_results[test_name] = {\n                'errors': errors,\n                'analysis': error_analysis\n            }\n            \n            # è©³ç´°å‡ºåŠ›\n            print(f\"  è»Œè·¡é•·: {len(test_trajectory)}\")\n            print(f\"  æ¤œå‡ºã‚¨ãƒ©ãƒ¼æ•°: {total_errors}\")\n            print(f\"  ã‚¨ãƒ©ãƒ¼ç‡: {error_rate:.4f}\")\n            print(f\"  å¹³å‡æ·±åˆ»åº¦: {mean_severity:.3f}\")\n            print(f\"  æœ€å¤§æ·±åˆ»åº¦: {max_severity:.3f}\")\n            print(f\"  ä½ç›¸ã‚¨ãƒ©ãƒ¼: {phase_errors}, æŒ¯å¹…ã‚¨ãƒ©ãƒ¼: {amplitude_errors}, ç›¸é–¢ã‚¨ãƒ©ãƒ¼: {correlation_errors}\")\n            print(f\"  ã‚¨ãƒ©ãƒ¼ã‚¯ãƒ©ã‚¹ã‚¿: {len(error_analysis.get('position_clusters', []))}\")\n            \n        except Exception as e:\n            print(f\"  ã‚¨ãƒ©ãƒ¼æ¤œå‡ºå¤±æ•—: {e}\")\n    \n    return error_results, detailed_results\n\ndef analyze_error_detection_results(error_results):\n    \"\"\"ã‚¨ãƒ©ãƒ¼æ¤œå‡ºçµæœã®åˆ†æ\"\"\"\n    if not error_results:\n        print(\"åˆ†æã™ã‚‹ã‚¨ãƒ©ãƒ¼æ¤œå‡ºçµæœãŒã‚ã‚Šã¾ã›ã‚“\")\n        return None\n    \n    df = pd.DataFrame(error_results)\n    \n    print(\"\\n=== ã‚¨ãƒ©ãƒ¼æ¤œå‡ºçµæœåˆ†æ ===\")\n    print(df.round(4))\n    \n    # ãƒã‚¤ã‚ºãƒ¬ãƒ™ãƒ«åˆ¥ã®çµ±è¨ˆ\n    print(\"\\n--- ãƒã‚¤ã‚ºãƒ¬ãƒ™ãƒ«åˆ¥çµ±è¨ˆ ---\")\n    noise_groups = df.groupby('noise_level')\n    \n    for noise_level, group in noise_groups:\n        print(f\"\\n{noise_level.upper()}ãƒã‚¤ã‚º:\")\n        print(f\"  å¹³å‡ã‚¨ãƒ©ãƒ¼ç‡: {group['error_rate'].mean():.4f}\")\n        print(f\"  å¹³å‡æ·±åˆ»åº¦: {group['mean_severity'].mean():.3f}\")\n        print(f\"  å¹³å‡ã‚¨ãƒ©ãƒ¼ã‚¯ãƒ©ã‚¹ã‚¿æ•°: {group['error_clusters'].mean():.1f}\")\n    \n    # ãƒ‡ãƒ¼ã‚¿ã‚¿ã‚¤ãƒ—åˆ¥ã®çµ±è¨ˆ\n    print(\"\\n--- ãƒ‡ãƒ¼ã‚¿ã‚¿ã‚¤ãƒ—åˆ¥çµ±è¨ˆ ---\")\n    type_groups = df.groupby('trajectory_type')\n    \n    for traj_type, group in type_groups:\n        print(f\"\\n{traj_type.upper()}ãƒ‡ãƒ¼ã‚¿:\")\n        print(f\"  å¹³å‡ã‚¨ãƒ©ãƒ¼ç‡: {group['error_rate'].mean():.4f}\")\n        print(f\"  å¹³å‡æ·±åˆ»åº¦: {group['mean_severity'].mean():.3f}\")\n        print(f\"  å¹³å‡ã‚¨ãƒ©ãƒ¼ã‚¯ãƒ©ã‚¹ã‚¿æ•°: {group['error_clusters'].mean():.1f}\")\n    \n    return df\n\ndef visualize_error_detection_results(error_results_df, trajectories, detailed_results):\n    \"\"\"ã‚¨ãƒ©ãƒ¼æ¤œå‡ºçµæœã®å¯è¦–åŒ–\"\"\"\n    if error_results_df is None or error_results_df.empty:\n        print(\"å¯è¦–åŒ–ã™ã‚‹ãƒ‡ãƒ¼ã‚¿ãŒã‚ã‚Šã¾ã›ã‚“\")\n        return\n    \n    fig, axes = plt.subplots(2, 3, figsize=(18, 12))\n    \n    # 1. ã‚¨ãƒ©ãƒ¼ç‡ã®æ¯”è¼ƒ\n    ax = axes[0, 0]\n    colors = ['lightblue' if 'bell' in name else \n              'orange' if 'moderate' in name else \n              'red' if 'noisy' in name else 'green' \n              for name in error_results_df['test_name']]\n    \n    bars = ax.bar(range(len(error_results_df)), error_results_df['error_rate'], color=colors)\n    ax.set_xlabel('è»Œè·¡')\n    ax.set_ylabel('ã‚¨ãƒ©ãƒ¼ç‡')\n    ax.set_title('è»Œè·¡åˆ¥ã‚¨ãƒ©ãƒ¼æ¤œå‡ºç‡')\n    ax.set_xticks(range(len(error_results_df)))\n    ax.set_xticklabels([name.replace('_', '\\n') for name in error_results_df['test_name']], rotation=45)\n    ax.grid(True, alpha=0.3)\n    \n    # å€¤ã‚’ãƒãƒ¼ã®ä¸Šã«è¡¨ç¤º\n    for bar, value in zip(bars, error_results_df['error_rate']):\n        ax.text(bar.get_x() + bar.get_width()/2, bar.get_height() + 0.001, \n                f'{value:.3f}', ha='center', va='bottom', fontsize=9)\n    \n    # 2. ã‚¨ãƒ©ãƒ¼ã®æ·±åˆ»åº¦åˆ†å¸ƒ\n    ax = axes[0, 1]\n    ax.scatter(error_results_df['error_rate'], error_results_df['max_severity'], \n               c=error_results_df['error_clusters'], s=100, alpha=0.7, cmap='viridis')\n    plt.colorbar(ax.collections[0], ax=ax, label='ã‚¨ãƒ©ãƒ¼ã‚¯ãƒ©ã‚¹ã‚¿æ•°')\n    ax.set_xlabel('ã‚¨ãƒ©ãƒ¼ç‡')\n    ax.set_ylabel('æœ€å¤§æ·±åˆ»åº¦')\n    ax.set_title('ã‚¨ãƒ©ãƒ¼ç‡ vs æ·±åˆ»åº¦')\n    \n    # è»Œè·¡åã‚’è¡¨ç¤º\n    for i, name in enumerate(error_results_df['test_name']):\n        ax.annotate(name.replace('_', '\\n'), \n                    (error_results_df['error_rate'].iloc[i], error_results_df['max_severity'].iloc[i]), \n                    fontsize=8, ha='center')\n    ax.grid(True, alpha=0.3)\n    \n    # 3. ã‚¨ãƒ©ãƒ¼ã‚¿ã‚¤ãƒ—ã®åˆ†å¸ƒ\n    ax = axes[0, 2]\n    x_pos = np.arange(len(error_results_df))\n    width = 0.25\n    \n    ax.bar(x_pos - width, error_results_df['phase_errors'], width, label='ä½ç›¸ã‚¨ãƒ©ãƒ¼', alpha=0.8)\n    ax.bar(x_pos, error_results_df['amplitude_errors'], width, label='æŒ¯å¹…ã‚¨ãƒ©ãƒ¼', alpha=0.8)\n    ax.bar(x_pos + width, error_results_df['correlation_errors'], width, label='ç›¸é–¢ã‚¨ãƒ©ãƒ¼', alpha=0.8)\n    \n    ax.set_xlabel('è»Œè·¡')\n    ax.set_ylabel('ã‚¨ãƒ©ãƒ¼æ•°')\n    ax.set_title('ã‚¨ãƒ©ãƒ¼ã‚¿ã‚¤ãƒ—åˆ¥åˆ†å¸ƒ')\n    ax.set_xticks(x_pos)\n    ax.set_xticklabels([name.replace('_', '\\n') for name in error_results_df['test_name']], rotation=45)\n    ax.legend()\n    ax.grid(True, alpha=0.3)\n    \n    # 4. ãƒã‚¤ã‚ºãƒ¬ãƒ™ãƒ«åˆ¥ã‚¨ãƒ©ãƒ¼ç‡\n    ax = axes[1, 0]\n    noise_summary = error_results_df.groupby('noise_level')['error_rate'].agg(['mean', 'std']).reset_index()\n    \n    bars = ax.bar(noise_summary['noise_level'], noise_summary['mean'], \n                  yerr=noise_summary['std'], capsize=5, alpha=0.7,\n                  color=['green', 'orange', 'red'])\n    ax.set_xlabel('ãƒã‚¤ã‚ºãƒ¬ãƒ™ãƒ«')\n    ax.set_ylabel('å¹³å‡ã‚¨ãƒ©ãƒ¼ç‡')\n    ax.set_title('ãƒã‚¤ã‚ºãƒ¬ãƒ™ãƒ«åˆ¥ã‚¨ãƒ©ãƒ¼æ¤œå‡ºæ€§èƒ½')\n    ax.grid(True, alpha=0.3)\n    \n    # 5. è»Œè·¡é•· vs ã‚¨ãƒ©ãƒ¼æ•°\n    ax = axes[1, 1]\n    scatter = ax.scatter(error_results_df['trajectory_length'], error_results_df['total_errors'], \n                        c=error_results_df['mean_severity'], s=100, alpha=0.7, cmap='plasma')\n    plt.colorbar(scatter, ax=ax, label='å¹³å‡æ·±åˆ»åº¦')\n    ax.set_xlabel('è»Œè·¡é•·')\n    ax.set_ylabel('ç·ã‚¨ãƒ©ãƒ¼æ•°')\n    ax.set_title('è»Œè·¡é•· vs ã‚¨ãƒ©ãƒ¼æ•°')\n    ax.grid(True, alpha=0.3)\n    \n    # 6. ã‚¨ãƒ©ãƒ¼ã‚¯ãƒ©ã‚¹ã‚¿åˆ†æ\n    ax = axes[1, 2]\n    bars = ax.bar(range(len(error_results_df)), error_results_df['error_clusters'], \n                  color=['lightblue' if 'bell' in name else \n                         'orange' if 'moderate' in name else \n                         'red' if 'noisy' in name else 'green' \n                         for name in error_results_df['test_name']])\n    ax.set_xlabel('è»Œè·¡')\n    ax.set_ylabel('ã‚¨ãƒ©ãƒ¼ã‚¯ãƒ©ã‚¹ã‚¿æ•°')\n    ax.set_title('è»Œè·¡åˆ¥ã‚¨ãƒ©ãƒ¼ã‚¯ãƒ©ã‚¹ã‚¿æ•°')\n    ax.set_xticks(range(len(error_results_df)))\n    ax.set_xticklabels([name.replace('_', '\\n') for name in error_results_df['test_name']], rotation=45)\n    ax.grid(True, alpha=0.3)\n    \n    plt.suptitle('å®Ÿãƒ‡ãƒ¼ã‚¿ã§ã®è¤‡ç´ ã‚¨ãƒ©ãƒ¼æ¤œå‡ºã‚·ã‚¹ãƒ†ãƒ æ€§èƒ½è©•ä¾¡', fontsize=16, fontweight='bold')\n    plt.tight_layout()\n    plt.savefig('complex_error_detection_real_data_results.png', dpi=300, bbox_inches='tight')\n    plt.show()\n\ndef test_quantum_entanglement_detection(trajectories):\n    \"\"\"é‡å­ã‚‚ã¤ã‚Œæ¤œå‡ºã®ãƒ†ã‚¹ãƒˆ\"\"\"\n    if len(trajectories) < 2:\n        print(\"ã‚‚ã¤ã‚Œæ¤œå‡ºã«ã¯å°‘ãªãã¨ã‚‚2ã¤ã®è»Œè·¡ãŒå¿…è¦ã§ã™\")\n        return None\n    \n    print(\"\\n=== é‡å­ã‚‚ã¤ã‚Œæ¤œå‡ºãƒ†ã‚¹ãƒˆ ===\")\n    \n    trajectory_names = list(trajectories.keys())\n    correlation_results = []\n    \n    for i in range(len(trajectory_names)):\n        for j in range(i + 1, len(trajectory_names)):\n            name1, name2 = trajectory_names[i], trajectory_names[j]\n            traj1, traj2 = trajectories[name1], trajectories[name2]\n            \n            # é•·ã•ã‚’åˆã‚ã›ã‚‹\n            min_len = min(len(traj1), len(traj2))\n            traj1_trimmed = traj1[:min_len]\n            traj2_trimmed = traj2[:min_len]\n            \n            # è¤‡ç´ ç›¸é–¢ã®è¨ˆç®—\n            correlation = compute_complex_correlation(traj1_trimmed, traj2_trimmed)\n            \n            # é‡å­ã‚‚ã¤ã‚Œæ¤œå‡º\n            entanglement = detect_quantum_entanglement(traj1_trimmed, traj2_trimmed)\n            \n            correlation_results.append({\n                'trajectory1': name1,\n                'trajectory2': name2,\n                'complex_correlation': correlation,\n                'phase_correlation': entanglement['phase_correlation'],\n                'amplitude_correlation': entanglement['amplitude_correlation'],\n                'entanglement_score': entanglement['score'],\n                'is_entangled': entanglement['entangled']\n            })\n            \n            print(f\"{name1} â†” {name2}:\")\n            print(f\"  è¤‡ç´ ç›¸é–¢: {correlation:.4f}\")\n            print(f\"  ã‚‚ã¤ã‚Œã‚¹ã‚³ã‚¢: {entanglement['score']:.4f}\")\n            print(f\"  ã‚‚ã¤ã‚Œåˆ¤å®š: {'YES' if entanglement['entangled'] else 'NO'}\")\n    \n    return correlation_results\n\ndef main():\n    \"\"\"ãƒ¡ã‚¤ãƒ³å®Ÿè¡Œé–¢æ•°\"\"\"\n    print(\"=\" * 60)\n    print(\"å®Ÿãƒ‡ãƒ¼ã‚¿ã‚’ç”¨ã„ãŸè¤‡ç´ ã‚¨ãƒ©ãƒ¼æ¤œå‡ºã‚·ã‚¹ãƒ†ãƒ ã®ãƒ†ã‚¹ãƒˆ\")\n    print(f\"å®Ÿè¡Œé–‹å§‹: {datetime.now()}\")\n    print(\"=\" * 60)\n    \n    # 1. å®Ÿãƒ‡ãƒ¼ã‚¿è»Œè·¡ã®èª­ã¿è¾¼ã¿\n    print(\"\\n1. å®Ÿãƒ‡ãƒ¼ã‚¿è»Œè·¡ã®èª­ã¿è¾¼ã¿ä¸­...\")\n    trajectories = load_real_trajectories()\n    \n    if not trajectories:\n        print(\"ã‚¨ãƒ©ãƒ¼: åˆ©ç”¨å¯èƒ½ãªè»Œè·¡ãƒ‡ãƒ¼ã‚¿ãŒã‚ã‚Šã¾ã›ã‚“\")\n        return\n    \n    print(f\"\\nç·è»Œè·¡æ•°: {len(trajectories)}\")\n    \n    # 2. ã‚¨ãƒ©ãƒ¼æ¤œå‡ºæ€§èƒ½ãƒ†ã‚¹ãƒˆ\n    print(\"\\n2. ã‚¨ãƒ©ãƒ¼æ¤œå‡ºæ€§èƒ½ãƒ†ã‚¹ãƒˆå®Ÿè¡Œä¸­...\")\n    error_results, detailed_results = test_error_detection_performance(trajectories)\n    \n    if error_results:\n        # 3. çµæœåˆ†æ\n        print(\"\\n3. ã‚¨ãƒ©ãƒ¼æ¤œå‡ºçµæœã®åˆ†æä¸­...\")\n        error_df = analyze_error_detection_results(error_results)\n        \n        # 4. å¯è¦–åŒ–\n        print(\"\\n4. çµæœã®å¯è¦–åŒ–ä¸­...\")\n        visualize_error_detection_results(error_df, trajectories, detailed_results)\n        \n        # 5. é‡å­ã‚‚ã¤ã‚Œæ¤œå‡ºãƒ†ã‚¹ãƒˆ\n        print(\"\\n5. é‡å­ã‚‚ã¤ã‚Œæ¤œå‡ºãƒ†ã‚¹ãƒˆå®Ÿè¡Œä¸­...\")\n        correlation_results = test_quantum_entanglement_detection(trajectories)\n        \n        # 6. çµæœä¿å­˜\n        error_df.to_csv('complex_error_detection_real_data_results.csv', index=False)\n        \n        if correlation_results:\n            correlation_df = pd.DataFrame(correlation_results)\n            correlation_df.to_csv('quantum_entanglement_detection_results.csv', index=False)\n            print(\"\\né‡å­ã‚‚ã¤ã‚Œæ¤œå‡ºçµæœã‚’ quantum_entanglement_detection_results.csv ã«ä¿å­˜\")\n        \n        # 7. ä¸»è¦ç™ºè¦‹ã®å ±å‘Š\n        print(\"\\n\" + \"=\" * 60)\n        print(\"ğŸ”¬ ä¸»è¦ãªç™ºè¦‹\")\n        print(\"=\" * 60)\n        \n        if len(error_results) > 0:\n            # æœ€ã‚‚å¤šãã®ã‚¨ãƒ©ãƒ¼ã‚’æ¤œå‡º\n            max_error_idx = error_df['total_errors'].idxmax()\n            max_error_name = error_df.loc[max_error_idx, 'test_name']\n            max_error_count = error_df.loc[max_error_idx, 'total_errors']\n            max_error_rate = error_df.loc[max_error_idx, 'error_rate']\n            \n            print(f\"\\nğŸš¨ æœ€ã‚‚å¤šãã®ã‚¨ãƒ©ãƒ¼ã‚’æ¤œå‡º:\")\n            print(f\"  {max_error_name}: {max_error_count}å€‹ã®ã‚¨ãƒ©ãƒ¼ï¼ˆç‡: {max_error_rate:.4f}ï¼‰\")\n            \n            # ãƒã‚¤ã‚ºãƒ¬ãƒ™ãƒ«åˆ¥ã®å¹³å‡ã‚¨ãƒ©ãƒ¼ç‡\n            bell_avg = error_df[error_df['trajectory_type'] == 'bell']['error_rate'].mean() if not error_df[error_df['trajectory_type'] == 'bell'].empty else 0\n            qv_avg = error_df[error_df['trajectory_type'] == 'qv']['error_rate'].mean() if not error_df[error_df['trajectory_type'] == 'qv'].empty else 0\n            \n            print(f\"\\nğŸ“Š ãƒ‡ãƒ¼ã‚¿ã‚¿ã‚¤ãƒ—åˆ¥ã‚¨ãƒ©ãƒ¼æ¤œå‡ºæ€§èƒ½:\")\n            print(f\"  BellçŠ¶æ…‹ãƒ‡ãƒ¼ã‚¿: å¹³å‡ã‚¨ãƒ©ãƒ¼ç‡ = {bell_avg:.4f}\")\n            print(f\"  Quantum Volumeãƒ‡ãƒ¼ã‚¿: å¹³å‡ã‚¨ãƒ©ãƒ¼ç‡ = {qv_avg:.4f}\")\n            \n            # ã‚‚ã¤ã‚Œæ¤œå‡ºçµæœ\n            if correlation_results:\n                entangled_pairs = sum(1 for r in correlation_results if r['is_entangled'])\n                total_pairs = len(correlation_results)\n                entanglement_rate = entangled_pairs / total_pairs if total_pairs > 0 else 0\n                \n                print(f\"\\nğŸ”— é‡å­ã‚‚ã¤ã‚Œæ¤œå‡º:\")\n                print(f\"  æ¤œå‡ºã•ã‚ŒãŸã‚‚ã¤ã‚Œãƒšã‚¢: {entangled_pairs}/{total_pairs} ({entanglement_rate:.2%})\")\n                \n                if entangled_pairs > 0:\n                    entangled_results = [r for r in correlation_results if r['is_entangled']]\n                    max_entanglement = max(entangled_results, key=lambda x: x['entanglement_score'])\n                    print(f\"  æœ€å¼·ã‚‚ã¤ã‚Œãƒšã‚¢: {max_entanglement['trajectory1']} â†” {max_entanglement['trajectory2']}\")\n                    print(f\"  ã€€ã€€ã€€ã€€ã‚¹ã‚³ã‚¢: {max_entanglement['entanglement_score']:.4f}\")\n        \n        print(f\"\\nğŸ’¡ ç§‘å­¦çš„æ„ç¾©:\")\n        print(f\"  - å®Ÿãƒ‡ãƒ¼ã‚¿ã§ã®è¤‡ç´ ã‚¨ãƒ©ãƒ¼æ¤œå‡ºã‚·ã‚¹ãƒ†ãƒ ã®æœ‰åŠ¹æ€§ã‚’å®Ÿè¨¼\")\n        print(f\"  - ãƒã‚¤ã‚ºãƒ¬ãƒ™ãƒ«ã«ã‚ˆã‚‹ã‚¨ãƒ©ãƒ¼ãƒ‘ã‚¿ãƒ¼ãƒ³ã®é•ã„ã‚’å®šé‡åŒ–\")\n        print(f\"  - BellçŠ¶æ…‹ã¨é‡å­ãƒœãƒªãƒ¥ãƒ¼ãƒ ãƒ‡ãƒ¼ã‚¿ã®ç‰¹æ€§å·®ã‚’æ˜ç¢ºåŒ–\")\n        print(f\"  - è¤‡ç´ ç›¸é–¢ã«ã‚ˆã‚‹é‡å­ã‚‚ã¤ã‚Œæ¤œå‡ºæ‰‹æ³•ã‚’æ¤œè¨¼\")\n    \n    print(f\"\\nå®Ÿè¡Œå®Œäº†: {datetime.now()}\")\n    print(\"ç”Ÿæˆã•ã‚ŒãŸãƒ•ã‚¡ã‚¤ãƒ«:\")\n    print(\"  - complex_error_detection_real_data_results.png\")\n    print(\"  - complex_error_detection_real_data_results.csv\")\n    print(\"  - quantum_entanglement_detection_results.csv\")\n\nif __name__ == \"__main__\":\n    main()