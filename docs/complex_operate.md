# ğŸš€ è¤‡ç´ æ¼”ç®—ã‚’æ´»ç”¨ã—ãŸCQTç†è«–ã®æ·±åŒ–ãƒ—ãƒ­ã‚¸ã‚§ã‚¯ãƒˆ

## ğŸ“‹ å®Ÿè£…ã™ã‚‹è¤‡ç´ æ¼”ç®—è§£æãƒ„ãƒ¼ãƒ«

### 1. complex_cqt_operations.py
```python
"""
CQTç†è«–ã®ãŸã‚ã®è¤‡ç´ æ¼”ç®—ãƒ©ã‚¤ãƒ–ãƒ©ãƒª
Wå­—è»Œè·¡ã®æ•°å­¦çš„ç‰¹æ€§ã‚’è§£æ˜
"""
import numpy as np
import pandas as pd
import matplotlib.pyplot as plt
from scipy import signal
from scipy.optimize import curve_fit
import seaborn as sns

class ComplexCQTAnalyzer:
    """è¤‡ç´ æ¼”ç®—ã«ã‚ˆã‚‹CQTè»Œè·¡ã®é«˜åº¦ãªè§£æ"""
    
    def __init__(self, trajectory_data):
        """
        trajectory_data: è¤‡ç´ æ•°ã®é…åˆ— (numpy array of complex numbers)
        """
        self.trajectory = np.array(trajectory_data)
        self.length = len(trajectory_data)
        
    def compute_instantaneous_properties(self):
        """ç¬é–“çš„ãªç‰©ç†é‡ã‚’è¨ˆç®—"""
        # è¤‡ç´ é€Ÿåº¦
        dt = 1  # æ¸¬å®šé–“éš”
        velocity = np.diff(self.trajectory) / dt
        
        # è¤‡ç´ åŠ é€Ÿåº¦
        acceleration = np.diff(velocity) / dt
        
        # ç¬é–“å‘¨æ³¢æ•°ï¼ˆä½ç›¸ã®æ™‚é–“å¾®åˆ†ï¼‰
        phase = np.unwrap(np.angle(self.trajectory))
        instantaneous_frequency = np.diff(phase) / dt
        
        # ç¬é–“æŒ¯å¹…å¤‰åŒ–ç‡
        amplitude = np.abs(self.trajectory)
        amplitude_rate = np.diff(amplitude) / dt
        
        # æ›²ç‡ï¼ˆè¤‡ç´ æ•°ãªã‚‰ã§ã¯ã®è¨ˆç®—ï¼‰
        if len(velocity) > 1:
            curvature = np.imag(acceleration * np.conj(velocity[:-1])) / (np.abs(velocity[:-1])**3)
        else:
            curvature = np.array([])
        
        return {
            'velocity': velocity,
            'acceleration': acceleration,
            'instant_frequency': instantaneous_frequency,
            'amplitude_rate': amplitude_rate,
            'curvature': curvature,
            'speed': np.abs(velocity),
            'direction': np.angle(velocity)
        }
    
    def analyze_w_pattern(self):
        """Wå­—ãƒ‘ã‚¿ãƒ¼ãƒ³ã®è¤‡ç´ æ•°çš„ç‰¹å¾´ã‚’æŠ½å‡º"""
        # 1. å·»ãæ•°ï¼ˆWinding Numberï¼‰
        angles = np.angle(self.trajectory)
        unwrapped = np.unwrap(angles)
        total_rotation = unwrapped[-1] - unwrapped[0]
        winding_number = total_rotation / (2 * np.pi)
        
        # 2. è¤‡ç´ ãƒ¢ãƒ¼ãƒ¡ãƒ³ãƒˆï¼ˆå½¢çŠ¶ã®ç‰¹å¾´ï¼‰
        centroid = np.mean(self.trajectory)
        centered = self.trajectory - centroid
        
        moments = {
            'order_1': np.mean(centered),
            'order_2': np.mean(centered**2),
            'order_3': np.mean(centered**3),
            'order_4': np.mean(centered**4)
        }
        
        # 3. è‡ªå·±ç›¸é–¢é–¢æ•°ï¼ˆè¤‡ç´ ç‰ˆï¼‰
        def complex_autocorrelation(z, lag):
            n = len(z)
            if lag >= n:
                return 0
            return np.mean(z[:-lag] * np.conj(z[lag:])) / np.mean(np.abs(z)**2)
        
        max_lag = min(50, self.length // 2)
        autocorr = [complex_autocorrelation(self.trajectory, lag) 
                   for lag in range(max_lag)]
        
        # 4. ãƒ•ãƒ©ã‚¯ã‚¿ãƒ«æ¬¡å…ƒã®æ¨å®š
        def box_counting_dimension(z, epsilon_range):
            dimensions = []
            for epsilon in epsilon_range:
                # è¤‡ç´ å¹³é¢ã‚’ã‚°ãƒªãƒƒãƒ‰ã«åˆ†å‰²
                real_bins = np.arange(z.real.min(), z.real.max() + epsilon, epsilon)
                imag_bins = np.arange(z.imag.min(), z.imag.max() + epsilon, epsilon)
                
                # å æœ‰ã•ã‚Œã¦ã„ã‚‹ãƒœãƒƒã‚¯ã‚¹ã‚’æ•°ãˆã‚‹
                hist, _, _ = np.histogram2d(z.real, z.imag, bins=[real_bins, imag_bins])
                n_boxes = np.sum(hist > 0)
                
                if n_boxes > 0:
                    dimensions.append((np.log(1/epsilon), np.log(n_boxes)))
            
            if len(dimensions) > 1:
                # ç·šå½¢ãƒ•ã‚£ãƒƒãƒ†ã‚£ãƒ³ã‚°ã§æ¬¡å…ƒã‚’æ¨å®š
                x, y = zip(*dimensions)
                slope, _ = np.polyfit(x, y, 1)
                return slope
            return None
        
        epsilon_range = np.logspace(-2, -0.5, 10)
        fractal_dim = box_counting_dimension(self.trajectory, epsilon_range)
        
        return {
            'winding_number': winding_number,
            'moments': moments,
            'autocorrelation': autocorr,
            'fractal_dimension': fractal_dim,
            'centroid': centroid,
            'spread': np.std(np.abs(centered))
        }
    
    def fourier_analysis(self):
        """è¤‡ç´ ãƒ•ãƒ¼ãƒªã‚¨è§£æ"""
        # è¤‡ç´ æ•°åˆ—ã®ãƒ•ãƒ¼ãƒªã‚¨å¤‰æ›
        fft_result = np.fft.fft(self.trajectory)
        frequencies = np.fft.fftfreq(self.length)
        
        # ãƒ‘ãƒ¯ãƒ¼ã‚¹ãƒšã‚¯ãƒˆãƒ«
        power_spectrum = np.abs(fft_result)**2
        
        # ä¸»è¦å‘¨æ³¢æ•°æˆåˆ†
        idx_sorted = np.argsort(power_spectrum)[::-1]
        dominant_freqs = frequencies[idx_sorted[:5]]
        dominant_powers = power_spectrum[idx_sorted[:5]]
        
        # ã‚¹ãƒšã‚¯ãƒˆãƒ«ã‚¨ãƒ³ãƒˆãƒ­ãƒ”ãƒ¼ï¼ˆå‘¨æ³¢æ•°åˆ†å¸ƒã®è¤‡é›‘ã•ï¼‰
        normalized_power = power_spectrum / np.sum(power_spectrum)
        spectral_entropy = -np.sum(normalized_power * np.log(normalized_power + 1e-10))
        
        # ä½ç›¸ã‚¹ãƒšã‚¯ãƒˆãƒ«
        phase_spectrum = np.angle(fft_result)
        
        return {
            'fft': fft_result,
            'frequencies': frequencies,
            'power_spectrum': power_spectrum,
            'phase_spectrum': phase_spectrum,
            'dominant_frequencies': dominant_freqs,
            'dominant_powers': dominant_powers,
            'spectral_entropy': spectral_entropy
        }
    
    def detect_phase_transitions(self):
        """è»Œè·¡ä¸­ã®ç›¸è»¢ç§»ç‚¹ã‚’æ¤œå‡º"""
        properties = self.compute_instantaneous_properties()
        
        # 1. é€Ÿåº¦ã®æ€¥æ¿€ãªå¤‰åŒ–ç‚¹
        speed = properties['speed']
        speed_changes = np.abs(np.diff(speed))
        threshold = np.mean(speed_changes) + 2 * np.std(speed_changes)
        velocity_transitions = np.where(speed_changes > threshold)[0]
        
        # 2. æ–¹å‘ã®æ€¥æ¿€ãªå¤‰åŒ–ç‚¹
        direction = properties['direction']
        direction_changes = np.abs(np.diff(direction))
        # è§’åº¦ã®å·»ãæˆ»ã—ã‚’è€ƒæ…®
        direction_changes = np.minimum(direction_changes, 2*np.pi - direction_changes)
        dir_threshold = np.mean(direction_changes) + 2 * np.std(direction_changes)
        direction_transitions = np.where(direction_changes > dir_threshold)[0]
        
        # 3. æ›²ç‡ã®æ¥µå€¤ç‚¹
        if len(properties['curvature']) > 0:
            curvature_peaks = signal.find_peaks(np.abs(properties['curvature']))[0]
        else:
            curvature_peaks = np.array([])
        
        return {
            'velocity_transitions': velocity_transitions,
            'direction_transitions': direction_transitions,
            'curvature_peaks': curvature_peaks,
            'all_transitions': np.unique(np.concatenate([
                velocity_transitions,
                direction_transitions,
                curvature_peaks
            ]))
        }
    
    def quantum_state_reconstruction(self):
        """è¤‡ç´ è»Œè·¡ã‹ã‚‰é‡å­çŠ¶æ…‹ã‚’æ¨å®š"""
        # è»Œè·¡ã‚’é‡å­çŠ¶æ…‹ã¨ã—ã¦è§£é‡ˆ
        # z = <0|Ïˆ> + i<1|Ïˆ> ã¨ä»®å®š
        
        # æ­£è¦åŒ–
        norms = np.abs(self.trajectory)
        max_norm = np.max(norms)
        
        # å„ç‚¹ã§ã®é‡å­çŠ¶æ…‹ã‚’æ¨å®š
        quantum_states = []
        for z in self.trajectory:
            # è¤‡ç´ æŒ¯å¹…ã‹ã‚‰ç¢ºç‡æŒ¯å¹…ã‚’è¨ˆç®—
            alpha = z.real / max_norm
            beta = z.imag / max_norm
            
            # æ­£è¦åŒ–
            norm = np.sqrt(abs(alpha)**2 + abs(beta)**2)
            if norm > 0:
                alpha /= norm
                beta /= norm
            
            # ãƒ–ãƒ­ãƒƒãƒ›çƒè¡¨ç¾
            theta = 2 * np.arccos(abs(alpha))
            phi = np.angle(beta) - np.angle(alpha)
            
            quantum_states.append({
                'alpha': alpha,
                'beta': beta,
                'theta': theta,
                'phi': phi,
                'prob_0': abs(alpha)**2,
                'prob_1': abs(beta)**2
            })
        
        return pd.DataFrame(quantum_states)
    
    def calculate_geometric_invariants(self):
        """å¹¾ä½•å­¦çš„ä¸å¤‰é‡ã®è¨ˆç®—"""
        # 1. å…¨é•·ï¼ˆè¤‡ç´ ç©åˆ†ï¼‰
        velocity = np.diff(self.trajectory)
        total_length = np.sum(np.abs(velocity))
        
        # 2. å›²ã‚€é¢ç©ï¼ˆã‚°ãƒªãƒ¼ãƒ³ã®å®šç†ï¼‰
        z = self.trajectory
        area = 0.5 * np.abs(np.sum(z[:-1] * np.conj(z[1:]) - z[1:] * np.conj(z[:-1])))
        
        # 3. é‡å¿ƒã‹ã‚‰ã®å¹³å‡è·é›¢
        centroid = np.mean(z)
        mean_distance = np.mean(np.abs(z - centroid))
        
        # 4. å›è»¢ä¸å¤‰ãƒ¢ãƒ¼ãƒ¡ãƒ³ãƒˆ
        centered = z - centroid
        I_0 = np.mean(np.abs(centered)**2)  # æ…£æ€§ãƒ¢ãƒ¼ãƒ¡ãƒ³ãƒˆ
        I_2 = np.abs(np.mean(centered**2))  # 2æ¬¡ãƒ¢ãƒ¼ãƒ¡ãƒ³ãƒˆ
        
        # 5. å½¢çŠ¶ã®éå¯¾ç§°æ€§
        asymmetry = I_2 / I_0 if I_0 > 0 else 0
        
        return {
            'total_length': total_length,
            'enclosed_area': area,
            'mean_distance': mean_distance,
            'moment_of_inertia': I_0,
            'asymmetry': asymmetry,
            'compactness': area / (total_length**2) if total_length > 0 else 0
        }

def visualize_complex_analysis(analyzer, save_prefix='complex_analysis'):
    """è¤‡ç´ è§£æçµæœã®åŒ…æ‹¬çš„ãªå¯è¦–åŒ–"""
    
    fig = plt.figure(figsize=(20, 16))
    
    # 1. è»Œè·¡ã¨ç¬é–“çš„æ€§è³ª
    ax1 = plt.subplot(3, 3, 1)
    trajectory = analyzer.trajectory
    props = analyzer.compute_instantaneous_properties()
    
    # é€Ÿåº¦ã«ã‚ˆã£ã¦è‰²åˆ†ã‘
    points = np.array([trajectory.real, trajectory.imag]).T.reshape(-1, 1, 2)
    segments = np.concatenate([points[:-1], points[1:]], axis=1)
    
    from matplotlib.collections import LineCollection
    lc = LineCollection(segments, cmap='viridis')
    lc.set_array(props['speed'])
    ax1.add_collection(lc)
    ax1.autoscale()
    plt.colorbar(lc, ax=ax1, label='Speed')
    ax1.set_title('Trajectory colored by speed')
    ax1.set_xlabel('Real')
    ax1.set_ylabel('Imaginary')
    
    # 2. ç¬é–“å‘¨æ³¢æ•°
    ax2 = plt.subplot(3, 3, 2)
    ax2.plot(props['instant_frequency'], 'b-', alpha=0.7)
    ax2.set_title('Instantaneous Frequency')
    ax2.set_xlabel('Time')
    ax2.set_ylabel('Frequency (rad/step)')
    ax2.grid(True, alpha=0.3)
    
    # 3. æ›²ç‡
    ax3 = plt.subplot(3, 3, 3)
    if len(props['curvature']) > 0:
        ax3.plot(props['curvature'], 'r-', alpha=0.7)
        ax3.set_title('Curvature')
        ax3.set_xlabel('Time')
        ax3.set_ylabel('Curvature')
        ax3.grid(True, alpha=0.3)
    
    # 4. è¤‡ç´ è‡ªå·±ç›¸é–¢
    ax4 = plt.subplot(3, 3, 4)
    w_features = analyzer.analyze_w_pattern()
    autocorr = w_features['autocorrelation']
    ax4.plot(np.abs(autocorr), 'g-', label='Magnitude')
    ax4.plot(np.real(autocorr), 'b--', label='Real', alpha=0.7)
    ax4.plot(np.imag(autocorr), 'r--', label='Imaginary', alpha=0.7)
    ax4.set_title('Complex Autocorrelation')
    ax4.set_xlabel('Lag')
    ax4.legend()
    ax4.grid(True, alpha=0.3)
    
    # 5. ãƒ‘ãƒ¯ãƒ¼ã‚¹ãƒšã‚¯ãƒˆãƒ«
    ax5 = plt.subplot(3, 3, 5)
    fourier = analyzer.fourier_analysis()
    freqs = fourier['frequencies'][:len(fourier['frequencies'])//2]
    power = fourier['power_spectrum'][:len(fourier['power_spectrum'])//2]
    ax5.semilogy(freqs, power, 'purple')
    ax5.set_title('Power Spectrum')
    ax5.set_xlabel('Frequency')
    ax5.set_ylabel('Power')
    ax5.grid(True, alpha=0.3)
    
    # 6. ä½ç›¸ã‚¹ãƒšã‚¯ãƒˆãƒ«
    ax6 = plt.subplot(3, 3, 6)
    phase = fourier['phase_spectrum'][:len(fourier['phase_spectrum'])//2]
    ax6.plot(freqs, phase, 'orange')
    ax6.set_title('Phase Spectrum')
    ax6.set_xlabel('Frequency')
    ax6.set_ylabel('Phase (rad)')
    ax6.grid(True, alpha=0.3)
    
    # 7. é‡å­çŠ¶æ…‹ã®é€²åŒ–
    ax7 = plt.subplot(3, 3, 7)
    quantum_states = analyzer.quantum_state_reconstruction()
    ax7.plot(quantum_states['prob_0'], 'b-', label='|0âŸ© probability')
    ax7.plot(quantum_states['prob_1'], 'r-', label='|1âŸ© probability')
    ax7.set_title('Quantum State Evolution')
    ax7.set_xlabel('Time')
    ax7.set_ylabel('Probability')
    ax7.legend()
    ax7.grid(True, alpha=0.3)
    
    # 8. ãƒ–ãƒ­ãƒƒãƒ›çƒã®è»Œè·¡ï¼ˆ2DæŠ•å½±ï¼‰
    ax8 = plt.subplot(3, 3, 8)
    theta = quantum_states['theta']
    phi = quantum_states['phi']
    x = np.sin(theta) * np.cos(phi)
    y = np.sin(theta) * np.sin(phi)
    ax8.plot(x, y, 'k-', alpha=0.5)
    ax8.scatter(x[0], y[0], color='green', s=100, label='Start')
    ax8.scatter(x[-1], y[-1], color='red', s=100, label='End')
    ax8.set_title('Bloch Sphere Trajectory (2D)')
    ax8.set_xlabel('X')
    ax8.set_ylabel('Y')
    ax8.legend()
    ax8.set_aspect('equal')
    
    # 9. ç‰¹å¾´ã‚µãƒãƒªãƒ¼
    ax9 = plt.subplot(3, 3, 9)
    ax9.axis('off')
    
    # ç‰¹å¾´ã‚’ãƒ†ã‚­ã‚¹ãƒˆã§è¡¨ç¤º
    invariants = analyzer.calculate_geometric_invariants()
    transitions = analyzer.detect_phase_transitions()
    
    summary_text = f"""
    W-Pattern Features:
    - Winding Number: {w_features['winding_number']:.3f}
    - Fractal Dimension: {w_features['fractal_dimension']:.3f}
    - Spectral Entropy: {fourier['spectral_entropy']:.3f}
    
    Geometric Invariants:
    - Total Length: {invariants['total_length']:.3f}
    - Enclosed Area: {invariants['enclosed_area']:.3f}
    - Asymmetry: {invariants['asymmetry']:.3f}
    
    Phase Transitions:
    - Velocity: {len(transitions['velocity_transitions'])} points
    - Direction: {len(transitions['direction_transitions'])} points
    - Curvature: {len(transitions['curvature_peaks'])} peaks
    """
    
    ax9.text(0.1, 0.5, summary_text, fontsize=12, verticalalignment='center',
             fontfamily='monospace', bbox=dict(boxstyle="round,pad=0.5", 
                                              facecolor="lightgray", alpha=0.8))
    
    plt.suptitle('Complex CQT Analysis Results', fontsize=16, fontweight='bold')
    plt.tight_layout()
    plt.savefig(f'{save_prefix}_complete.png', dpi=300, bbox_inches='tight')
    plt.show()
    
    return fig

# å®Ÿè¡Œä¾‹
def run_complex_analysis(trajectory_data, name='experiment'):
    """
    trajectory_data: è¤‡ç´ æ•°ã®é…åˆ—ã¾ãŸã¯ãƒªã‚¹ãƒˆ
    """
    print(f"=== {name} ã®è¤‡ç´ æ¼”ç®—è§£æ ===")
    
    analyzer = ComplexCQTAnalyzer(trajectory_data)
    
    # 1. ç¬é–“çš„æ€§è³ª
    instant_props = analyzer.compute_instantaneous_properties()
    print(f"\nç¬é–“çš„æ€§è³ª:")
    print(f"  å¹³å‡é€Ÿåº¦: {np.mean(instant_props['speed']):.4f}")
    print(f"  æœ€å¤§åŠ é€Ÿåº¦: {np.max(np.abs(instant_props['acceleration'])):.4f}")
    
    # 2. Wå­—ãƒ‘ã‚¿ãƒ¼ãƒ³è§£æ
    w_features = analyzer.analyze_w_pattern()
    print(f"\nWå­—ãƒ‘ã‚¿ãƒ¼ãƒ³ã®ç‰¹å¾´:")
    print(f"  å·»ãæ•°: {w_features['winding_number']:.3f}")
    print(f"  ãƒ•ãƒ©ã‚¯ã‚¿ãƒ«æ¬¡å…ƒ: {w_features['fractal_dimension']:.3f}")
    
    # 3. ãƒ•ãƒ¼ãƒªã‚¨è§£æ
    fourier = analyzer.fourier_analysis()
    print(f"\nãƒ•ãƒ¼ãƒªã‚¨è§£æ:")
    print(f"  ä¸»è¦å‘¨æ³¢æ•°: {fourier['dominant_frequencies'][:3]}")
    print(f"  ã‚¹ãƒšã‚¯ãƒˆãƒ«ã‚¨ãƒ³ãƒˆãƒ­ãƒ”ãƒ¼: {fourier['spectral_entropy']:.3f}")
    
    # 4. å¹¾ä½•å­¦çš„ä¸å¤‰é‡
    invariants = analyzer.calculate_geometric_invariants()
    print(f"\nå¹¾ä½•å­¦çš„ä¸å¤‰é‡:")
    print(f"  å…¨é•·: {invariants['total_length']:.3f}")
    print(f"  å›²ã‚€é¢ç©: {invariants['enclosed_area']:.3f}")
    print(f"  ã‚³ãƒ³ãƒ‘ã‚¯ãƒˆæ€§: {invariants['compactness']:.4f}")
    
    # 5. ç›¸è»¢ç§»æ¤œå‡º
    transitions = analyzer.detect_phase_transitions()
    print(f"\nç›¸è»¢ç§»ç‚¹:")
    print(f"  æ¤œå‡ºã•ã‚ŒãŸè»¢ç§»ç‚¹ç·æ•°: {len(transitions['all_transitions'])}")
    
    # å¯è¦–åŒ–
    visualize_complex_analysis(analyzer, save_prefix=f'complex_{name}')
    
    return analyzer
```

### 2. ã‚¨ãƒ©ãƒ¼æ¤œå‡ºã®è¤‡ç´ æ¼”ç®—ç‰ˆ

```python
# complex_error_detection.py
"""
è¤‡ç´ æ¼”ç®—ã«ã‚ˆã‚‹ã‚¨ãƒ©ãƒ¼æ¤œå‡ºã®é«˜åº¦åŒ–
"""

class ComplexErrorDetector:
    """è¤‡ç´ æ¼”ç®—ã‚’ç”¨ã„ãŸé‡å­ã‚¨ãƒ©ãƒ¼æ¤œå‡º"""
    
    def __init__(self, reference_trajectory):
        self.reference = np.array(reference_trajectory)
        self.analyzer = ComplexCQTAnalyzer(reference_trajectory)
        self.reference_features = self._extract_reference_features()
    
    def _extract_reference_features(self):
        """å‚ç…§è»Œè·¡ã®ç‰¹å¾´ã‚’æŠ½å‡º"""
        return {
            'fourier': self.analyzer.fourier_analysis(),
            'w_pattern': self.analyzer.analyze_w_pattern(),
            'invariants': self.analyzer.calculate_geometric_invariants()
        }
    
    def detect_errors(self, test_trajectory, window_size=20):
        """è¤‡ç´ æ¼”ç®—ã«ã‚ˆã‚‹ã‚¨ãƒ©ãƒ¼æ¤œå‡º"""
        test = np.array(test_trajectory)
        errors_detected = []
        
        for i in range(len(test) - window_size):
            window = test[i:i+window_size]
            
            # 1. ä½ç›¸ã‚³ãƒ’ãƒ¼ãƒ¬ãƒ³ã‚¹ã®ç ´ã‚Œ
            phase_error = self._detect_phase_decoherence(window, i)
            if phase_error:
                errors_detected.append(phase_error)
            
            # 2. æŒ¯å¹…ã®ç•°å¸¸
            amplitude_error = self._detect_amplitude_anomaly(window, i)
            if amplitude_error:
                errors_detected.append(amplitude_error)
            
            # 3. è»Œè·¡ã®ä¸é€£ç¶šæ€§
            discontinuity = self._detect_trajectory_discontinuity(window, i)
            if discontinuity:
                errors_detected.append(discontinuity)
        
        return errors_detected
    
    def _detect_phase_decoherence(self, window, position):
        """ä½ç›¸ã®ãƒ‡ã‚³ãƒ’ãƒ¼ãƒ¬ãƒ³ã‚¹ã‚’æ¤œå‡º"""
        # ä½ç›¸ã®åˆ†æ•£ã‚’è¨ˆç®—
        phases = np.angle(window)
        phase_variance = np.var(np.unwrap(phases))
        
        # å‚ç…§è»Œè·¡ã®ä½ç›¸åˆ†æ•£ã¨æ¯”è¼ƒ
        ref_phases = np.angle(self.reference)
        ref_variance = np.var(np.unwrap(ref_phases))
        
        if phase_variance > 3 * ref_variance:  # 3ÏƒåŸºæº–
            return {
                'type': 'phase_decoherence',
                'position': position,
                'severity': phase_variance / ref_variance,
                'phase_variance': phase_variance
            }
        return None
    
    def _detect_amplitude_anomaly(self, window, position):
        """æŒ¯å¹…ã®ç•°å¸¸ã‚’æ¤œå‡º"""
        amplitudes = np.abs(window)
        
        # æŒ¯å¹…ã®æ€¥æ¿€ãªå¤‰åŒ–
        amp_diff = np.abs(np.diff(amplitudes))
        if np.max(amp_diff) > 0.5:  # é–¾å€¤
            return {
                'type': 'amplitude_jump',
                'position': position + np.argmax(amp_diff),
                'severity': np.max(amp_diff),
                'amplitude_change': np.max(amp_diff)
            }
        return None
    
    def _detect_trajectory_discontinuity(self, window, position):
        """è»Œè·¡ã®ä¸é€£ç¶šæ€§ã‚’æ¤œå‡º"""
        # è¤‡ç´ å¾®åˆ†ã«ã‚ˆã‚‹é€Ÿåº¦è¨ˆç®—
        velocity = np.diff(window)
        
        # é€Ÿåº¦ã®æ€¥æ¿€ãªå¤‰åŒ–ï¼ˆåŠ é€Ÿåº¦ï¼‰
        acceleration = np.diff(velocity)
        
        if len(acceleration) > 0:
            max_acc = np.max(np.abs(acceleration))
            if max_acc > 1.0:  # é–¾å€¤
                return {
                    'type': 'trajectory_discontinuity',
                    'position': position + np.argmax(np.abs(acceleration)),
                    'severity': max_acc,
                    'acceleration': max_acc
                }
        return None
    
    def classify_error_type(self, error_info):
        """ã‚¨ãƒ©ãƒ¼ã®ç¨®é¡ã‚’åˆ†é¡"""
        if error_info['type'] == 'phase_decoherence':
            if error_info['severity'] > 5:
                return 'severe_decoherence'
            else:
                return 'mild_decoherence'
        
        elif error_info['type'] == 'amplitude_jump':
            if error_info['amplitude_change'] > 0.8:
                return 'bit_flip_error'
            else:
                return 'amplitude_damping'
        
        elif error_info['type'] == 'trajectory_discontinuity':
            return 'measurement_error'
        
        return 'unknown_error'
```

### 3. å®Ÿè¡Œã‚¹ã‚¯ãƒªãƒ—ãƒˆ

```python
# run_complex_cqt_analysis.py
"""
è¤‡ç´ æ¼”ç®—ã‚’æ´»ç”¨ã—ãŸCQTè§£æã®å®Ÿè¡Œ
"""
import numpy as np
import pandas as pd
from complex_cqt_operations import ComplexCQTAnalyzer, run_complex_analysis
from complex_error_detection import ComplexErrorDetector

def main():
    print("=== è¤‡ç´ æ¼”ç®—ã«ã‚ˆã‚‹CQTè§£æé–‹å§‹ ===")
    
    # 1. ãƒ‡ãƒ¼ã‚¿ã®èª­ã¿è¾¼ã¿ï¼ˆã‚ãªãŸã®å®Ÿãƒ‡ãƒ¼ã‚¿ï¼‰
    # ã“ã“ã¯å®Ÿéš›ã®ãƒ‡ãƒ¼ã‚¿ãƒ‘ã‚¹ã«ç½®ãæ›ãˆã¦ãã ã•ã„
    trajectory_data = load_your_w_trajectory()  # è¤‡ç´ æ•°ã®é…åˆ—
    
    # 2. è¤‡ç´ æ¼”ç®—è§£æã®å®Ÿè¡Œ
    analyzer = run_complex_analysis(trajectory_data, name='IBM_W_pattern')
    
    # 3. ã‚¨ãƒ©ãƒ¼æ¤œå‡ºã®å®Ÿè¡Œ
    print("\n=== è¤‡ç´ æ¼”ç®—ã«ã‚ˆã‚‹ã‚¨ãƒ©ãƒ¼æ¤œå‡º ===")
    
    # å‚ç…§è»Œè·¡ï¼ˆã‚¨ãƒ©ãƒ¼ãªã—ï¼‰ã¨ãƒ†ã‚¹ãƒˆè»Œè·¡ï¼ˆã‚¨ãƒ©ãƒ¼ã‚ã‚Šï¼‰
    clean_trajectory = load_clean_trajectory()
    noisy_trajectory = load_noisy_trajectory()
    
    detector = ComplexErrorDetector(clean_trajectory)
    errors = detector.detect_errors(noisy_trajectory)
    
    print(f"\næ¤œå‡ºã•ã‚ŒãŸã‚¨ãƒ©ãƒ¼æ•°: {len(errors)}")
    for error in errors[:5]:  # æœ€åˆã®5å€‹ã‚’è¡¨ç¤º
        error_type = detector.classify_error_type(error)
        print(f"  ä½ç½®{error['position']}: {error_type} (æ·±åˆ»åº¦: {error['severity']:.2f})")
    
    # 4. è¤‡ç´ ç›¸é–¢è§£æ
    print("\n=== è¤‡ç´ ç›¸é–¢è§£æ ===")
    
    # 2ã¤ã®é‡å­ãƒ“ãƒƒãƒˆé–“ã®ç›¸é–¢
    if hasattr(trajectory_data, 'qubit1') and hasattr(trajectory_data, 'qubit2'):
        correlation = compute_complex_correlation(
            trajectory_data.qubit1, 
            trajectory_data.qubit2
        )
        print(f"è¤‡ç´ ç›¸é–¢ä¿‚æ•°: {correlation:.4f}")
    
    print("\n=== è§£æå®Œäº† ===")

def compute_complex_correlation(traj1, traj2):
    """2ã¤ã®è¤‡ç´ è»Œè·¡é–“ã®ç›¸é–¢ã‚’è¨ˆç®—"""
    # è¤‡ç´ ç›¸é–¢ä¿‚æ•°
    z1 = np.array(traj1)
    z2 = np.array(traj2)
    
    # ä¸­å¿ƒåŒ–
    z1_centered = z1 - np.mean(z1)
    z2_centered = z2 - np.mean(z2)
    
    # è¤‡ç´ ç›¸é–¢
    correlation = np.sum(z1_centered * np.conj(z2_centered)) / \
                 np.sqrt(np.sum(np.abs(z1_centered)**2) * np.sum(np.abs(z2_centered)**2))
    
    return np.abs(correlation)

if __name__ == "__main__":
    main()
```

## ğŸ¯ å®Ÿè£…ã™ã‚‹è¤‡ç´ æ¼”ç®—ã®ç‰¹å¾´

1. **ç¬é–“çš„ç‰©ç†é‡**
   - è¤‡ç´ é€Ÿåº¦ãƒ»åŠ é€Ÿåº¦
   - ç¬é–“å‘¨æ³¢æ•°
   - æ›²ç‡

2. **Wå­—ãƒ‘ã‚¿ãƒ¼ãƒ³ã®æ•°å­¦çš„ç‰¹å¾´**
   - å·»ãæ•°
   - ãƒ•ãƒ©ã‚¯ã‚¿ãƒ«æ¬¡å…ƒ
   - è¤‡ç´ ãƒ¢ãƒ¼ãƒ¡ãƒ³ãƒˆ

3. **ãƒ•ãƒ¼ãƒªã‚¨è§£æ**
   - ãƒ‘ãƒ¯ãƒ¼ã‚¹ãƒšã‚¯ãƒˆãƒ«
   - ä½ç›¸ã‚¹ãƒšã‚¯ãƒˆãƒ«
   - ä¸»è¦å‘¨æ³¢æ•°æˆåˆ†

4. **å¹¾ä½•å­¦çš„ä¸å¤‰é‡**
   - è»Œè·¡ã®å…¨é•·
   - å›²ã‚€é¢ç©
   - å½¢çŠ¶ã®éå¯¾ç§°æ€§

5. **é‡å­çŠ¶æ…‹æ¨å®š**
   - ãƒ–ãƒ­ãƒƒãƒ›çƒè¡¨ç¾
   - ç¢ºç‡æŒ¯å¹…ã®æ™‚é–“ç™ºå±•

ã“ã‚Œã‚‰ã®è¤‡ç´ æ¼”ç®—ã«ã‚ˆã‚Šã€å˜ãªã‚‹2Dãƒ—ãƒ­ãƒƒãƒˆã§ã¯è¦‹ãˆãªã„æ·±ã„ç‰©ç†çš„ãƒ»æ•°å­¦çš„æ§‹é€ ãŒæ˜ã‚‰ã‹ã«ãªã‚Šã¾ã™ï¼