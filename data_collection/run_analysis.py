"""
åé›†ã—ãŸãƒ‡ãƒ¼ã‚¿ã‚’è§£æã™ã‚‹æœ€åˆã®ã‚¹ãƒ†ãƒƒãƒ—
CQTç†è«–ã«ã‚ˆã‚‹è¤‡ç´ æ•°è§£æã¸ã®æº–å‚™
"""
import pandas as pd
import numpy as np
import matplotlib.pyplot as plt
import ast
import os

def load_collected_data():
    """åé›†ã•ã‚ŒãŸãƒ‡ãƒ¼ã‚¿ã‚’èª­ã¿è¾¼ã‚€"""
    data_files = {
        'bell_states': 'collected_data/bell_states/bell_measurement_data.csv',
        'rotation_sweep': 'collected_data/custom_experiments/rotation_sweep_data.csv',
        'noise_characterization': 'collected_data/error_characterization/noise_sweep_data.csv',
        'vqe_landscape': 'collected_data/vqe_results/vqe_landscape_H2.csv'
    }
    
    loaded_data = {}
    
    for name, filepath in data_files.items():
        if os.path.exists(filepath):
            df = pd.read_csv(filepath)
            loaded_data[name] = df
            print(f"âœ“ {name}: {df.shape[0]} records loaded")
        else:
            print(f"âœ— {name}: file not found at {filepath}")
    
    return loaded_data

def analyze_bell_data(bell_data):
    """BellçŠ¶æ…‹ãƒ‡ãƒ¼ã‚¿ã®è©³ç´°è§£æ"""
    print("\n=== BellçŠ¶æ…‹ãƒ‡ãƒ¼ã‚¿ã®æ§‹é€ è§£æ ===")
    print(f"æ¸¬å®šçŠ¶æ…‹æ•°: {len(bell_data)}")
    print(f"ç·ã‚·ãƒ§ãƒƒãƒˆæ•°: {bell_data['shots'].sum()}")
    print(f"çŠ¶æ…‹ã®ç¨®é¡: {list(bell_data['state'].unique())}")
    
    # counts ã‚«ãƒ©ãƒ ã®è§£æ
    print("\n=== æ¸¬å®šçµæœã®è©³ç´° ===")
    
    for idx, row in bell_data.iterrows():
        state = row['state']
        counts_str = row['counts']
        shots = row['shots']
        
        # æ–‡å­—åˆ—ã¨ã—ã¦ä¿å­˜ã•ã‚ŒãŸdictã‚’å¾©å…ƒ
        try:
            # NumPyå‹ã®æ–‡å­—åˆ—è¡¨ç¾ã‚’å‡¦ç†
            counts_str = counts_str.replace("np.str_('", "'").replace("np.int64(", "").replace("')", "'").replace(")", "")
            counts = ast.literal_eval(counts_str)
            
            print(f"\n{state}:")
            print(f"  ç·æ¸¬å®šæ•°: {shots}")
            print(f"  æ¸¬å®šçµæœ: {counts}")
            
            # ç¢ºç‡è¨ˆç®—
            total_counts = sum(counts.values())
            probabilities = {outcome: count/total_counts for outcome, count in counts.items()}
            print(f"  ç¢ºç‡åˆ†å¸ƒ: {probabilities}")
            
            # BellçŠ¶æ…‹ã®ç†è«–å€¤ã¨ã®æ¯”è¼ƒ
            if state in ['phi_plus', 'phi_minus']:
                # |Î¦Â±âŸ© = (|00âŸ© Â± |11âŸ©)/âˆš2
                expected_prob = 0.5
                actual_prob_00 = probabilities.get('00', 0)
                actual_prob_11 = probabilities.get('11', 0)
                
                print(f"  ç†è«–å€¤: |00âŸ©=0.5, |11âŸ©=0.5")
                print(f"  å®Ÿæ¸¬å€¤: |00âŸ©={actual_prob_00:.3f}, |11âŸ©={actual_prob_11:.3f}")
                print(f"  èª¤å·®: |00âŸ©={abs(actual_prob_00-0.5):.4f}, |11âŸ©={abs(actual_prob_11-0.5):.4f}")
                
            elif state in ['psi_plus', 'psi_minus']:
                # |Î¨Â±âŸ© = (|01âŸ© Â± |10âŸ©)/âˆš2
                expected_prob = 0.5
                actual_prob_01 = probabilities.get('01', 0)
                actual_prob_10 = probabilities.get('10', 0)
                
                print(f"  ç†è«–å€¤: |01âŸ©=0.5, |10âŸ©=0.5")
                print(f"  å®Ÿæ¸¬å€¤: |01âŸ©={actual_prob_01:.3f}, |10âŸ©={actual_prob_10:.3f}")
                print(f"  èª¤å·®: |01âŸ©={abs(actual_prob_01-0.5):.4f}, |10âŸ©={abs(actual_prob_10-0.5):.4f}")
            
        except Exception as e:
            print(f"  ãƒ‡ãƒ¼ã‚¿è§£æã‚¨ãƒ©ãƒ¼: {e}")
            print(f"  ç”Ÿã® counts ãƒ‡ãƒ¼ã‚¿: {counts_str}")

def analyze_rotation_data(rotation_data):
    """å›è»¢ã‚¹ã‚¤ãƒ¼ãƒ—ãƒ‡ãƒ¼ã‚¿ã®è§£æ"""
    print("\n=== å›è»¢ã‚¹ã‚¤ãƒ¼ãƒ—ãƒ‡ãƒ¼ã‚¿ã®è§£æ ===")
    print(f"ãƒ‡ãƒ¼ã‚¿ãƒã‚¤ãƒ³ãƒˆæ•°: {len(rotation_data)}")
    print(f"è§’åº¦ç¯„å›²: {rotation_data['angle'].min():.3f} - {rotation_data['angle'].max():.3f} rad")
    
    # ç†è«–å€¤ã¨å®Ÿæ¸¬å€¤ã®æ¯”è¼ƒ
    mean_error = np.mean(np.abs(rotation_data['probability_1'] - rotation_data['theoretical_prob_1']))
    max_error = np.max(np.abs(rotation_data['probability_1'] - rotation_data['theoretical_prob_1']))
    
    print(f"å¹³å‡æ¸¬å®šèª¤å·®: {mean_error:.4f}")
    print(f"æœ€å¤§æ¸¬å®šèª¤å·®: {max_error:.4f}")
    
    # çµ±è¨ˆçš„å“è³ªè©•ä¾¡
    correlation = np.corrcoef(rotation_data['probability_1'], rotation_data['theoretical_prob_1'])[0,1]
    print(f"ç†è«–å€¤ã¨ã®ç›¸é–¢ä¿‚æ•°: {correlation:.4f}")
    
    return {
        'mean_error': mean_error,
        'max_error': max_error,
        'correlation': correlation
    }

def analyze_noise_data(noise_data):
    """ãƒã‚¤ã‚ºç‰¹æ€§ãƒ‡ãƒ¼ã‚¿ã®è§£æ"""
    print("\n=== ãƒã‚¤ã‚ºç‰¹æ€§ãƒ‡ãƒ¼ã‚¿ã®è§£æ ===")
    print(f"ãƒã‚¤ã‚ºãƒ¬ãƒ™ãƒ«æ•°: {len(noise_data)}")
    print(f"ãƒã‚¤ã‚ºç¯„å›²: {noise_data['noise_level'].min():.3f} - {noise_data['noise_level'].max():.3f}")
    
    # å¿ å®Ÿåº¦ã®åŠ£åŒ–åˆ†æ
    for idx, row in noise_data.iterrows():
        noise_level = row['noise_level']
        fidelity = row['fidelity']
        print(f"  ãƒã‚¤ã‚º {noise_level:.3f}: å¿ å®Ÿåº¦ {fidelity:.4f}")
    
    # ãƒã‚¤ã‚ºè€æ€§ã®é–¾å€¤åˆ†æ
    high_fidelity_threshold = 0.95
    acceptable_noise = noise_data[noise_data['fidelity'] >= high_fidelity_threshold]
    
    if not acceptable_noise.empty:
        max_acceptable_noise = acceptable_noise['noise_level'].max()
        print(f"\né«˜å¿ å®Ÿåº¦ç¶­æŒå¯èƒ½ãªæœ€å¤§ãƒã‚¤ã‚ºãƒ¬ãƒ™ãƒ«: {max_acceptable_noise:.3f}")
    else:
        print("\né«˜å¿ å®Ÿåº¦ã‚’ç¶­æŒã™ã‚‹ãƒã‚¤ã‚ºãƒ¬ãƒ™ãƒ«ãŒè¦‹ã¤ã‹ã‚Šã¾ã›ã‚“")

def prepare_for_cqt_analysis(loaded_data):
    """CQTè§£æã«å‘ã‘ãŸãƒ‡ãƒ¼ã‚¿æº–å‚™çŠ¶æ³ã®è©•ä¾¡"""
    print("\n=== CQTè§£æã¸ã®æº–å‚™çŠ¶æ³ ===")
    
    quality_score = 0
    max_score = 4
    
    # 1. BellçŠ¶æ…‹ãƒ‡ãƒ¼ã‚¿ã®å“è³ª
    if 'bell_states' in loaded_data:
        bell_data = loaded_data['bell_states']
        if len(bell_data) == 4:  # 4ã¤ã®BellçŠ¶æ…‹å…¨ã¦
            quality_score += 1
            print("âœ“ BellçŠ¶æ…‹ãƒ‡ãƒ¼ã‚¿: 4çŠ¶æ…‹å®Œå‚™")
        else:
            print("âœ— BellçŠ¶æ…‹ãƒ‡ãƒ¼ã‚¿: ä¸å®Œå…¨")
    else:
        print("âœ— BellçŠ¶æ…‹ãƒ‡ãƒ¼ã‚¿: æœªåé›†")
    
    # 2. å›è»¢ãƒ‡ãƒ¼ã‚¿ã®å“è³ª
    if 'rotation_sweep' in loaded_data:
        rotation_stats = analyze_rotation_data(loaded_data['rotation_sweep'])
        if rotation_stats['correlation'] > 0.95:
            quality_score += 1
            print("âœ“ å›è»¢ãƒ‡ãƒ¼ã‚¿: é«˜å“è³ªï¼ˆç›¸é–¢ > 0.95ï¼‰")
        else:
            print("âš  å›è»¢ãƒ‡ãƒ¼ã‚¿: å“è³ªè¦æ”¹å–„")
    else:
        print("âœ— å›è»¢ãƒ‡ãƒ¼ã‚¿: æœªåé›†")
    
    # 3. ãƒã‚¤ã‚ºãƒ‡ãƒ¼ã‚¿ã®å“è³ª
    if 'noise_characterization' in loaded_data:
        quality_score += 1
        print("âœ“ ãƒã‚¤ã‚ºãƒ‡ãƒ¼ã‚¿: åé›†æ¸ˆã¿")
    else:
        print("âœ— ãƒã‚¤ã‚ºãƒ‡ãƒ¼ã‚¿: æœªåé›†")
    
    # 4. VQEãƒ‡ãƒ¼ã‚¿ã®å“è³ª
    if 'vqe_landscape' in loaded_data:
        vqe_data = loaded_data['vqe_landscape']
        if len(vqe_data) >= 100:  # ååˆ†ãªãƒ‡ãƒ¼ã‚¿ãƒã‚¤ãƒ³ãƒˆ
            quality_score += 1
            print("âœ“ VQEãƒ‡ãƒ¼ã‚¿: ååˆ†ãªãƒ‡ãƒ¼ã‚¿ãƒã‚¤ãƒ³ãƒˆ")
        else:
            print("âš  VQEãƒ‡ãƒ¼ã‚¿: ãƒ‡ãƒ¼ã‚¿ãƒã‚¤ãƒ³ãƒˆä¸è¶³")
    else:
        print("âœ— VQEãƒ‡ãƒ¼ã‚¿: æœªåé›†")
    
    # ç·åˆè©•ä¾¡
    print(f"\nç·åˆå“è³ªã‚¹ã‚³ã‚¢: {quality_score}/{max_score}")
    
    if quality_score == max_score:
        print("ğŸ¯ CQTè¤‡ç´ æ•°è§£æã«é€²ã‚€æº–å‚™å®Œäº†ï¼")
        return True
    elif quality_score >= 2:
        print("âš  éƒ¨åˆ†çš„ã«CQTè§£æå¯èƒ½ã€ä¸€éƒ¨ãƒ‡ãƒ¼ã‚¿ã®æ”¹å–„æ¨å¥¨")
        return True
    else:
        print("âœ— ãƒ‡ãƒ¼ã‚¿å“è³ªä¸è¶³ã€å†åé›†ãŒå¿…è¦")
        return False

def visualize_data_overview(loaded_data):
    """åé›†ãƒ‡ãƒ¼ã‚¿ã®æ¦‚è¦ã‚’å¯è¦–åŒ–"""
    fig, axes = plt.subplots(2, 2, figsize=(15, 12))
    
    # 1. BellçŠ¶æ…‹ã®æ¸¬å®šåˆ†å¸ƒ
    if 'bell_states' in loaded_data:
        bell_data = loaded_data['bell_states']
        ax = axes[0, 0]
        
        # å„BellçŠ¶æ…‹ã®æ¸¬å®šæ•°ã‚’ãƒ—ãƒ­ãƒƒãƒˆ
        states = bell_data['state'].tolist()
        shots = bell_data['shots'].tolist()
        
        ax.bar(states, shots, alpha=0.7, color=['blue', 'red', 'green', 'orange'])
        ax.set_title('Bell States Measurement Count')
        ax.set_ylabel('Number of Shots')
        ax.tick_params(axis='x', rotation=45)
    
    # 2. å›è»¢ã‚¹ã‚¤ãƒ¼ãƒ—ã®ç†è«– vs å®Ÿæ¸¬
    if 'rotation_sweep' in loaded_data:
        rotation_data = loaded_data['rotation_sweep']
        ax = axes[0, 1]
        
        ax.plot(rotation_data['angle'], rotation_data['theoretical_prob_1'], 'r--', 
                alpha=0.8, label='Theoretical')
        ax.plot(rotation_data['angle'], rotation_data['probability_1'], 'b-', 
                alpha=0.7, label='Measured')
        ax.set_title('Rotation Sweep: Theory vs Measurement')
        ax.set_xlabel('Angle (rad)')
        ax.set_ylabel('Probability |1âŸ©')
        ax.legend()
        ax.grid(True, alpha=0.3)
    
    # 3. ãƒã‚¤ã‚º vs å¿ å®Ÿåº¦
    if 'noise_characterization' in loaded_data:
        noise_data = loaded_data['noise_characterization']
        ax = axes[1, 0]
        
        ax.plot(noise_data['noise_level'], noise_data['fidelity'], 'ro-', alpha=0.7)
        ax.set_title('Noise Level vs Fidelity')
        ax.set_xlabel('Noise Level')
        ax.set_ylabel('Fidelity')
        ax.grid(True, alpha=0.3)
    
    # 4. VQEã‚¨ãƒãƒ«ã‚®ãƒ¼ãƒ©ãƒ³ãƒ‰ã‚¹ã‚±ãƒ¼ãƒ—ï¼ˆã‚µãƒ³ãƒ—ãƒ«ï¼‰
    if 'vqe_landscape' in loaded_data:
        vqe_data = loaded_data['vqe_landscape']
        ax = axes[1, 1]
        
        # 2Dãƒ’ãƒ¼ãƒˆãƒãƒƒãƒ—ç”¨ã®ãƒ‡ãƒ¼ã‚¿æº–å‚™
        theta_unique = sorted(vqe_data['theta'].unique())
        phi_unique = sorted(vqe_data['phi'].unique())
        
        if len(theta_unique) > 1 and len(phi_unique) > 1:
            energy_matrix = np.zeros((len(phi_unique), len(theta_unique)))
            
            for i, phi in enumerate(phi_unique):
                for j, theta in enumerate(theta_unique):
                    energy_val = vqe_data[(vqe_data['theta'] == theta) & 
                                         (vqe_data['phi'] == phi)]['energy']
                    if not energy_val.empty:
                        energy_matrix[i, j] = energy_val.iloc[0]
            
            im = ax.imshow(energy_matrix, aspect='auto', origin='lower')
            ax.set_title('VQE Energy Landscape')
            ax.set_xlabel('Theta Index')
            ax.set_ylabel('Phi Index')
            plt.colorbar(im, ax=ax, label='Energy')
    
    plt.tight_layout()
    plt.savefig('collected_data/analysis_overview.png', dpi=150, bbox_inches='tight')
    print("\nå¯è¦–åŒ–çµæœã‚’ collected_data/analysis_overview.png ã«ä¿å­˜ã—ã¾ã—ãŸ")
    plt.show()

def main():
    """ãƒ¡ã‚¤ãƒ³è§£æå®Ÿè¡Œ"""
    print("=== CQT Theory - åé›†ãƒ‡ãƒ¼ã‚¿è§£æé–‹å§‹ ===")
    
    # ãƒ‡ãƒ¼ã‚¿èª­ã¿è¾¼ã¿
    loaded_data = load_collected_data()
    
    if not loaded_data:
        print("è§£æå¯èƒ½ãªãƒ‡ãƒ¼ã‚¿ãŒè¦‹ã¤ã‹ã‚Šã¾ã›ã‚“ã€‚å…ˆã«ãƒ‡ãƒ¼ã‚¿åé›†ã‚’å®Ÿè¡Œã—ã¦ãã ã•ã„ã€‚")
        return
    
    # å„ãƒ‡ãƒ¼ã‚¿ã‚»ãƒƒãƒˆã®è©³ç´°è§£æ
    if 'bell_states' in loaded_data:
        analyze_bell_data(loaded_data['bell_states'])
    
    if 'rotation_sweep' in loaded_data:
        analyze_rotation_data(loaded_data['rotation_sweep'])
    
    if 'noise_characterization' in loaded_data:
        analyze_noise_data(loaded_data['noise_characterization'])
    
    # CQTè§£ææº–å‚™çŠ¶æ³ã®è©•ä¾¡
    ready_for_cqt = prepare_for_cqt_analysis(loaded_data)
    
    # å¯è¦–åŒ–
    visualize_data_overview(loaded_data)
    
    # æ¬¡ã®ã‚¹ãƒ†ãƒƒãƒ—ã®ææ¡ˆ
    print("\n=== æ¬¡ã®ã‚¹ãƒ†ãƒƒãƒ— ===")
    if ready_for_cqt:
        print("1. complex_analysis.py ã§è¤‡ç´ æ•°å¤‰æ›ã‚’å®Ÿè¡Œ")
        print("2. pattern_discovery.py ã§BellçŠ¶æ…‹ã‚·ã‚°ãƒãƒãƒ£ã‚’ç™ºè¦‹")
        print("3. CQT v3ãƒˆãƒ©ãƒƒã‚«ãƒ¼ã¨ã®çµ±åˆãƒ†ã‚¹ãƒˆ")
    else:
        print("1. ãƒ‡ãƒ¼ã‚¿å“è³ªã®æ”¹å–„")
        print("2. è¿½åŠ ãƒ‡ãƒ¼ã‚¿ã®åé›†")
        print("3. ãƒã‚¤ã‚ºãƒ¢ãƒ‡ãƒ«ã®èª¿æ•´")

if __name__ == "__main__":
    main()